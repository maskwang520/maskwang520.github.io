<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[flink整合kafka实现消费和生产]]></title>
    <url>%2F2018%2F03%2F28%2Fflink%E6%95%B4%E5%90%88kafka%E5%AE%9E%E7%8E%B0%E6%B6%88%E8%B4%B9%E5%92%8C%E7%94%9F%E4%BA%A7%2F</url>
    <content type="text"><![CDATA[1. flink通常整合kafka实现消费和生产。在很大原因上是由于kafka很适合流处理在我们平常的业务场景中，仅读取，写入和存储数据流是不够的，更多目的是启用流的实时处理。在Kafka中，流处理器是指从输入topic获取连续数据流，对该输入执行一些处理，并生成连续数据流以输出topic的任何内容。例如，零售应用程序可能会接受销售和装运的输入流，并输出一系列重新排序和根据此数据计算出的价格调整。可以直接使用生产者API和消费者API进行简单的处理。然而，对于更复杂的转换，Kafka提供完全集成的Streams API。这允许构建应用程序进行非平凡的处理，从而计算聚合关闭流或将流连接在一起。在这过程中，fiink整合kafka来实现对流数据的处理是一个非常好的选择。 2. 采用flink的Api，实现消费者。往kafka的“flinktest”这个topic不断发布消息，然后经过flink的消费之后，输出处理的时间和处理的字符串。采用的是flink1.4.2 和kafka1.0.0pom文件如下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.maskwang.flink&lt;/groupId&gt; &lt;artifactId&gt;flink_kafka&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;flink_kafka&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;flink.version&gt;1.4.2&lt;/flink.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-java&lt;/artifactId&gt; &lt;version&gt;$&#123;flink.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-streaming-java_2.11&lt;/artifactId&gt; &lt;version&gt;$&#123;flink.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-clients_2.11&lt;/artifactId&gt; &lt;version&gt;$&#123;flink.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.apache.flink/flink-connector-kafka-0.10 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-connector-kafka-0.10_2.11&lt;/artifactId&gt; &lt;version&gt;1.4.2&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;shade&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;artifactSet&gt; &lt;excludes&gt; &lt;exclude&gt;com.google.code.findbugs:jsr305&lt;/exclude&gt; &lt;exclude&gt;org.slf4j:*&lt;/exclude&gt; &lt;exclude&gt;log4j:*&lt;/exclude&gt; &lt;/excludes&gt; &lt;/artifactSet&gt; &lt;filters&gt; &lt;filter&gt; &lt;!-- Do not copy the signatures in the META-INF folder. Otherwise, this might cause SecurityExceptions when using the JAR. --&gt; &lt;artifact&gt;*:*&lt;/artifact&gt; &lt;excludes&gt; &lt;exclude&gt;META-INF/*.SF&lt;/exclude&gt; &lt;exclude&gt;META-INF/*.DSA&lt;/exclude&gt; &lt;exclude&gt;META-INF/*.RSA&lt;/exclude&gt; &lt;/excludes&gt; &lt;/filter&gt; &lt;/filters&gt; &lt;transformers&gt; &lt;transformer implementation="org.apache.maven.plugins.shade.resource.ManifestResourceTransformer"&gt; &lt;mainClass&gt;com.maskwang.flink.ReadFromKafka&lt;/mainClass&gt; &lt;/transformer&gt; &lt;/transformers&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt;&lt;/project&gt; 业务逻辑如下12345678910111213141516171819202122232425262728293031323334353637package com.maskwang.flink;import java.util.Date;import java.util.Properties;import org.apache.flink.api.common.functions.MapFunction;import org.apache.flink.streaming.api.datastream.DataStream;import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;import org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer010;import org.apache.flink.streaming.util.serialization.SimpleStringSchema;public class ReadFromKafka &#123; public static void main(String[] args) throws Exception &#123; // 构建环境 StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); Properties properties = new Properties(); //这里是由一个kafka properties.setProperty("bootstrap.servers", "localhost:9092"); properties.setProperty("group.id", "flink_consumer"); //第一个参数是topic的名称 DataStream&lt;String&gt; stream=env.addSource(new FlinkKafkaConsumer010("flinktest", new SimpleStringSchema(), properties)); stream.map(new MapFunction&lt;String, String&gt;() &#123; @Override public String map(String value) throws Exception &#123; return new Date().toString()+": "+value; &#125; &#125;).print(); env.execute(); &#125;&#125; 没有运用到集群，所以只需要添加一个ip地址就可以。如果是集群，则把其他的地址加入到这里。 我采用的是flink1.4.2。所以这里使用123456789101112131415161718192021222324252627**注意这里有个坑，之前我不是采用这种打包方式，导致会产生如下异常**```javajava.lang.NoClassDefFoundError: org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumer010 at com.maskwang.flink.ReadFromKafka.main(ReadFromKafka.java:22) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:525) at org.apache.flink.client.program.PackagedProgram.invokeInteractiveModeForExecution(PackagedProgram.java:417) at org.apache.flink.client.program.ClusterClient.run(ClusterClient.java:396) at org.apache.flink.client.CliFrontend.executeProgram(CliFrontend.java:802) at org.apache.flink.client.CliFrontend.run(CliFrontend.java:282) at org.apache.flink.client.CliFrontend.parseParameters(CliFrontend.java:1054) at org.apache.flink.client.CliFrontend$1.call(CliFrontend.java:1101) at org.apache.flink.client.CliFrontend$1.call(CliFrontend.java:1098) at org.apache.flink.runtime.security.HadoopSecurityContext$$Lambda$8/989447607.run(Unknown Source) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:422) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807) at org.apache.flink.runtime.security.HadoopSecurityContext.runSecured(HadoopSecurityContext.java:41) at org.apache.flink.client.CliFrontend.main(CliFrontend.java:1098)Caused by: java.lang.ClassNotFoundException: org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer010 at java.net.URLClassLoader.findClass(URLClassLoader.java:381) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ... 19 more 运行状态如下： 向kafka的topic推送数据 flink作为客户对订阅topic实现消费并输出 3. flink作为生产者向topic推送数据参考文章https://www.zhihu.com/question/28925721https://github.com/tgrall/kafka-flink-101]]></content>
      <categories>
        <category>flink</category>
      </categories>
      <tags>
        <tag>flink</tag>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解Java8Lambada表达式]]></title>
    <url>%2F2018%2F03%2F24%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java8Lambada%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;Lambda 表达式是一种匿名函数(对 Java 而言这并不完全正确，但现在姑且这么认为)，简单地说，它是没有声明的方法，也即没有访问修饰符、返回值声明和名字。&emsp;&emsp;你可以将其想做一种速记，在你需要使用某个方法的地方写上它。当某个方法只使用一次，而且定义很简短，使用这种速记替代之尤其有效，这样，你就不必在类中费力写声明与方法了。Java 中的 Lambda 表达式通常使用 (argument) -&gt; (body) 语法书写，例如：12(arg1, arg2...) -&gt; &#123; body &#125;(type1 arg1, type2 arg2...) -&gt; &#123; body &#125; 常见的写法如下12345(int a, int b) -&gt; &#123; return a + b; &#125;() -&gt; System.out.println("Hello World");(String s) -&gt; &#123; System.out.println(s); &#125;() -&gt; 42() -&gt; &#123; return 3.1415 &#125;; 2. Lambda 表达式的结构 一个 Lambda 表达式可以有零个或多个参数 参数的类型既可以明确声明，也可以根据上下文来推断。例如：(int a)与(a)效果相同 所有参数需包含在圆括号内，参数之间用逗号相隔。例如：(a, b) 或 (int a, int b) 或 (String a, int b, float c) 空圆括号代表参数集为空。例如：() -&gt; 42 当只有一个参数，且其类型可推导时，圆括号（）可省略。例如：a -&gt; return a*a Lambda 表达式的主体可包含零条或多条语句 如果 Lambda 表达式的主体只有一条语句，花括号{}可省略。匿名函数的返回类型与该主体表达式一致 如果 Lambda 表达式的主体包含一条以上语句，则表达式必须包含在花括号{}中（形成代码块）。匿名函数的返回类型与代码块的返回类型一致，若没有返回则为空 3. 函数式接口&emsp;&emsp;函数式接口是只包含一个抽象方法声明的接口.java.lang.Runnable 就是一种函数式接口，在 Runnable 接口中只声明了一个方法 void run()，相似地，ActionListener 接口也是一种函数式接口，我们使用匿名内部类来实例化函数式接口的对象，有了 Lambda 表达式，这一方式可以得到简化。每个 Lambda 表达式都能隐式地赋值给函数式接口，例如，我们可以通过 Lambda 表达式创建 Runnable 接口的引用。1Runnable r = () -&gt; System.out.println("hello world"); 编译器会把lambada表达式当做一个函数来编译. 4. 常见的函数式接口4.1 Runnable123456Runnable runnable = ()-&gt;&#123; System.out.println(Thread.currentThread().getName());&#125;; Thread thread = new Thread(runnable);thread.start(); Runnable只有一个run函数,且run函数没有参数4.2 Consumer接口Consumer接口接收一个参数,不返回参数1234567public static void consumerFun(int value, Consumer&lt;Integer&gt; c) &#123; c.accept(value);&#125;//调用consumerFun(1,(value)-&gt;&#123; System.out.println(value);&#125;); 4.3 BinConsumer接口与Consumer接口一样,只不过接收两个参数,返回0个参数1234567public static void binConsumerFun(String a, String b, BiConsumer&lt;String, String&gt; binc) &#123; binc.accept(a, b);&#125;//调用binConsumerFun("hello", "maskwang", (a,b)-&gt;&#123; System.out.println(a+b)&#125;); 4.4 Predication作用接收一个参数,返回一个boolean值12345public static boolean predicateFun(int value, Predicate&lt;Integer&gt; pre) &#123; return pre.test(value);&#125;//调用System.out.println(predicateFun(3, x-&gt;x==3)); 4.5 Supplier作用是接收0个参数,返回一个值12345public static int supplierFun(Supplier&lt;Integer&gt; supplier) &#123; return supplier.get();&#125;//调用System.out.println(supplierFun(()-&gt;1)); 4.5 Comparatorlambada表达式实现Comparator1234567List&lt;Integer&gt; list = new ArrayList&lt;&gt;();list.add(1);list.add(3);list.add(2);list.sort((a,b) -&gt; &#123;return a&gt;b?-1:1;&#125;); //另一种方式list.forEach(System.out::println) 4.6 集合的操作实现集合的遍历12345List&lt;Integer&gt; list = new ArrayList&lt;&gt;();list.add(1);list.add(3);list.add(2);list.forEach((value)-&gt;System.out.println(value)); 5. Lambda表达式与匿名内部类的联系和区别联系： lambda表达式创建的对象与匿名内部类生成的对象一样，可以直接调用接口中继承的默认方法。 区别： 匿名内部类可以为任意接口创建实例，不管接口中包含多少个抽象方法，只要在匿名内部类中实现所有抽象方法即可。 但在lambda表达式中只能为函数式接口创建实例。 匿名内部类可以为抽象类甚至普通类创建实例；但lambda表达式只能为函数式接口创建实例。 匿名内部类实现的抽象方法可以允许调用接口中定义默认方法。但lambda表达式的代码块不允许调用接口中定义默认方法。 6. 总结Lambda 表达式赋予了 Java 相较于其他函数式编程语言缺失的特性，结合虚拟扩展方法之类的特性，Lambda 表达式能写出一些极好的代码。希望能在以后写代码的过程中,把这些用上去,使整个代码看起来很简洁. ps: ::运算符是方法的引用,用这种方式可以简单代替Lambada1234String::valueOf x -&gt; String.valueOf(x)Object::toString x -&gt; x.toString()x::toString () -&gt; x.toString()ArrayList::new () -&gt; new ArrayList&lt;&gt;() 参考文章 深入浅出 Java 8 Lambda 表达式 Lambda表达式与匿名内部类的联系和区别]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>Lambada表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解HTTPS协议]]></title>
    <url>%2F2018%2F03%2F24%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3HTTPS%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[HTTS协议实际就是标准的HTTP协议加上SSL/TLS层.它能防止我们的信息被窃取,暴露出不安全.或者进入钓鱼网址.通过下面这个讲解,我希望能明白SSL/TLS层到底为我们做了哪些事情,才能保证我们的信息安全. 1. HTTPS到底做了哪些事情HTTPS采用众所周知和理解的HTTP协议，并简单地将SSL / TLS加密层层叠在其上。服务器和客户端仍然使用相同的HTTP，但通过安全的SSL连接来加密和解密他们的请求和响应。 SSL层有两个主要目的： 保证你是在跟真正的服务器通信,而不是伪装的服务器. 保证只有真正的服务器才能解密你发送的信息.同时,也只有你才能解密服务器跟你发送消息.就是保证是你跟真正的服务器在通信,这过程中没有第三者. 在这过程中,其他人还是可以中途截取到你发送的信息,但是是加密的,它们拿到也无法解密. 2. SSL/TLS是如何建立连接的客户端和服务器端通过握手来建立连接的，目的有以下3点。 保证客户端正在和正确的服务器通信（反之亦然） 有关各方已就“密码套件”达成一致，该密码套件包括将用于交换数据的加密算法 对密匙达成一致，双方使用相同的密匙 一旦建立连接，双方就可以使用商定的算法和密钥将消息安全地发送给对方。我们将握手分为三个主要阶段 - Hello，证书交换和密钥交换。 Hello - 握手从客户端发送ClientHello消息开始。这包含服务器通过SSL/TLS连接到客户端所需的所有信息，包括它支持的各种密码套件和最大SSL/TLS版本。服务器响应ServerHello，其中包含客户端所需的类似信息，包括基于客户端有关哪个密码套件和SSL/TLS版本将被使用的偏好的决定。 证书交换 - 现在联系已建立，服务器必须向客户证明其身份。这是通过使用SSL证书来实现的，该证书与其护照非常相似。 SSL证书包含各种数据，包括所有者的名称，所连接的属性（例如域），证书的公钥，数字签名以及有关证书有效日期的信息。客户端检查它是隐式信任证书，还是验证它是否被其隐含信任的几个证书颁发机构（CA）之一验证和信任。请注意，服务器也可以要求证书来证明客户的身份，但这通常只发生在非常敏感的应用程序中。 密钥交换 - 客户端和服务器交换的实际消息数据的加密将使用对称加密算法完成，其确切性质在Hello阶段已经达成一致。对称算法使用单个密钥进行加密和解密，与需要公钥/私钥对的非对称算法相反。双方需要就这个单一的对称密钥达成一致，这个安全使用非对称加密和服务器的公钥/私钥完成的过程。客户端先用非对称加密算法的公钥把通信过程中需要的私钥传给服务端，服务端用私钥解读出以后通信过程中的私钥。 客户端生成一个用于对称加密算法的随机密钥。它使用在Hello阶段同意的算法和服务器的公钥（在其SSL证书上找到）对其进行加密。它将这个加密的密钥发送到服务器，在那里使用服务器的私钥解密，并且握手的有趣部分已完成。双方都非常高兴，他们正在与正确的人交谈，并秘密地同意了一个密钥，以对称加密的方式加密他们将要发送的数据。 HTTP请求和响应现在可以通过形成明文消息然后加密并发送来发送。另一方是唯一知道如何解密此消息的人，因此中间人攻击者无法读取或修改他们可能拦截的任何请求。 3. 证书对于请求方来说，它怎么能确定它所得到的公钥一定是从目标主机那里发布的，而且没有被篡改过呢？亦或者请求的目标主机本本身就从事窃取用户信息的不正当行为呢？这时候，我们需要有一个权威的值得信赖的第三方机构(一般是由政府审核并授权的机构)来统一对外发放主机机构的公钥，只要请求方这种机构获取公钥，就避免了上述问题的发生。用户首先产生自己的密钥对，并将公共密钥及部分个人身份信息传送给认证中心。认证中心在核实身份后，将执行一些必要的步骤，以确信请求确实由用户发送而来，然后，认证中心将发给用户一个数字证书，该证书内包含用户的个人信息和他的公钥信息，同时还附有认证中心的签名信息(根证书私钥签名)。用户就可以使用自己的数字证书进行相关的各种活动。数字证书由独立的证书发行机构发布，数字证书各不相同，每种证书可提供不同级别的可信度。证书的验证是通过验证证书的数字签名(CA的公钥来解开签名,并与原文hash之后的摘要做对比). 4. 数字签名数字签名技术就是对“非对称密钥加解密”和“数字摘要“两项技术的应用，它将摘要信息用发送者的私钥加密，与原文一起传送给接收者。 接收者只有用发送者的公钥才能解密被加密的摘要信息，然后用HASH函数对收到的原文产生一个摘要信息，与解密的摘要信息对比。 如果相同，则说明收到的信息是完整的，在传输过程中没有被修改，否则说明信息被修改过，因此数字签名能够验证信息的完整性。数字签名的过程如下： 明文 –&gt; hash运算 –&gt; 摘要 –&gt; 私钥加密 –&gt; 数字签名 数字签名有两种功效： 能确定消息确实是由发送方签名并发出来的，因为别人假冒不了发送方的签名。 数字签名能确定消息的完整性。 真个HTTPS的握手过程如下 5. 总结HTTPS不是不可破解的，并且SSL协议必须随着新攻击被发现和压制而不断发展。但它仍然是一种传递秘密数据的的方式，无需关心谁看到您的消息。当然，这里没有提到许多实现细节，例如握手消息的确切格式和顺序，在不需要重新协商密钥和密码套件的情况下选择最近会话的简短握手，以及在每个阶段可用的众多不同的加密选项。关键要记住的是，虽然HTTPS可以保证数据安全地连接到目的地，但它绝不会保护您（作为用户或开发人员）抵御XSS或数据库泄漏或任何其他事情 。看看威尔史密斯，“Walk in shadow, move in silence, guard against extra-terrestrial violence”。 参考文章:http://www.ruanyifeng.com/blog/2011/08/what_is_a_digital_signature.htmlhttps://robertheaton.com/2014/03/27/how-does-https-actually-work/http://www.wxtlife.com/2016/03/27/%E8%AF%A6%E8%A7%A3https%E6%98%AF%E5%A6%82%E4%BD%95%E7%A1%AE%E4%BF%9D%E5%AE%89%E5%85%A8%E7%9A%84%EF%BC%9F/#u6570_u5B57_u8BC1_u4E66]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>HTTP/2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重拾jdk源码重点系列-8:ThreadLocal源码分析]]></title>
    <url>%2F2018%2F03%2F20%2F%E9%87%8D%E6%8B%BEjdk%E6%BA%90%E7%A0%81%E9%87%8D%E7%82%B9%E7%B3%BB%E5%88%97-8-ThreadLocal%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[ThreadLocal的作用是提供线程内的局部变量，说白了，就是在各线程内部创建一个变量的副本，相比于使用各种锁机制访问变量，ThreadLocal的思想就是用空间换时间，使各线程都能访问属于自己这一份的变量副本，变量值不互相干扰，减少同一个线程内的多个函数或者组件之间一些公共变量传递的复杂度。我们看看源码对于ThreadLocal的描述. This class provides thread-local variables. These variables differ from their normal counterparts in that each thread that accesses one (via its {@code get} or {@code set} method) has its own, independently initialized copy of the variable. {@code ThreadLocal} instances are typically private static fields in classes that wish to associate state with a thread (e.g.,a user ID or Transaction ID). 2. 基本用法实现的功能是给每个线程都有自己唯一的id,且是自增的．12345678910111213141516171819202122232425262728public class ThreadId &#123; public static final AtomicInteger NEXTId = new AtomicInteger(0); public static final ThreadLocal&lt;Integer&gt; THREADID = new ThreadLocal&lt;Integer&gt;() &#123; @Override protected Integer initialValue() &#123; return NEXTId.incrementAndGet(); &#125; &#125;; public static int getThreadId() &#123; return THREADID.get(); &#125; public static void main(String[] args) throws Exception &#123; for (int i = 0; i &lt; 10; i++) &#123; new Thread(new Runnable() &#123; public void run() &#123; System.out.println(ThreadId.getThreadId()); &#125; &#125;).start(); &#125; Thread.sleep(1000 * 3); &#125;&#125; 3. ThreadLocal的数据结构12345678910private final int threadLocalHashCode = nextHashCode();private static AtomicInteger nextHashCode = new AtomicInteger(); private static final int HASH_INCREMENT = 0x61c88647;private static int nextHashCode() &#123; return nextHashCode.getAndAdd(HASH_INCREMENT); // &#125; 从上面可以看出,每创建一个ThreadLocal变量,hashcode就会增加0x61c88647.hashcode的作用就是在后面根据在map中根据hash比较ThreadLocalMap的key,从而判定是否相等.之所以用这个数是因为可以是2的幂尽可能分布均匀在每个线程内部,都会维护一个 ThreadLocal.ThreadLocalMap threadLocals的成员变量,参考下面这个实例图．每个变量能够将变量私有化的根本原因还是在于ThreadLocalMap.如图所示,实线是强引用,虚线是弱引用,如果ThreadLocalRef的引用没有了,则只剩下Entry对ThreadLocal有弱引用,我们知道弱引用活不过下次Gc(Entry是弱引用)12345678910111213141516171819202122232425262728293031323334static class ThreadLocalMap &#123; static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125; /** * The initial capacity -- MUST be a power of two. */ private static final int INITIAL_CAPACITY = 16; /** * The table, resized as necessary. * table.length MUST always be a power of two. */ private Entry[] table; /** * The number of entries in the table. */ private int size = 0; /** * The next size value at which to resize. */ private int threshold; // Default to 0 /** * Set the resize threshold to maintain at worst a 2/3 load factor. */ private void setThreshold(int len) &#123; threshold = len * 2 / 3; &#125; 4. get()返回存储在ThreadLocalMap中value12345678910111213public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; return setInitialValue(); &#125; 从ＴhreadLocal中获取值的步骤分为如下几步． 获取当前线程的ThreadLocalMap 把当前的ThreadLocal对象为key,去获取值.若存在,且不为null,则返回.否则设置map,初始化 setInitialValue()12345678910private T setInitialValue() &#123; T value = initialValue(); //1 Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); //若存在,则设置key,value就可以 else createMap(t, value); //不存在则创建ThreadLocalMap return value; &#125; initialValue()返回值为null,说明初始值为null createMap()1234567ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) &#123; table = new Entry[INITIAL_CAPACITY]; // 1 初始化数组,初始大小为16 int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); //定位到数组下标 table[i] = new Entry(firstKey, firstValue); size = 1; setThreshold(INITIAL_CAPACITY); //设置阈值 &#125; firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1)相当于一个求余的方法,这要求INITIAL_CAPACITY为2的n次幂.经常采用这种方法来求响应的hash值对应在数组中的位置. 5. set()往ThreadLocalMap设置值12345678public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); &#125; set()的逻辑如下 获取当前线程的ThreadLocalMap 如果map不为null,则把传入的值设置进去 否则创建新的map,createMap()和前面get()createMap()中的一样. set(ThreadLocal&lt;?&gt; key, Object value)123456789101112131415161718192021222324252627private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); //找到在数组中的位置 for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; ThreadLocal&lt;?&gt; k = e.get(); //hash的线性探测法 if (k == key) &#123; //遇到相等,则替换 e.value = value; return; &#125; if (k == null) &#123; //发现key为null,则需要把这个key所在的Entry设置为null,然后把这个key后面的元素做再hash往前移动 replaceStaleEntry(key, value, i); return; &#125; &#125; tab[i] = new Entry(key, value); //第一次遇到Entry为空,则放入进去.运行到这里,说明这个过程中没有key为null的Entry int sz = ++size; if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) //在清理完成后,看当前大小有没有超过阈值,看是否需要rehash rehash(); &#125; set()方法的逻辑是: 找到在数组中的位置 遇到相等则替换,如果在这过程中遇到key为null,执行第三步 执行replaceStaleEntry() 经过2,3两步还没终止,说明遇到Entry为null,则把key,value组成Entry,放入到这个位置. 添加了新的元素,需要判断达没达到阈值,达到则需要再hash replaceStaleEntry()123456789101112131415161718192021222324252627282930313233343536373839404142private void replaceStaleEntry(ThreadLocal&lt;?&gt; key, Object value, int staleSlot) &#123; Entry[] tab = table; int len = tab.length; Entry e; int slotToExpunge = staleSlot; //key为null的Entry,在数组中的下标 for (int i = prevIndex(staleSlot, len); //从该位置往前找 (e = tab[i]) != null; i = prevIndex(i, len)) if (e.get() == null) slotToExpunge = i; //记录下key为null的点 for (int i = nextIndex(staleSlot, len); //从该位置往后走 (e = tab[i]) != null; i = nextIndex(i, len)) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) &#123; e.value = value; tab[i] = tab[staleSlot]; //若找到,把该Entry与传入进来位置的Entry做个交换 tab[staleSlot] = e; if (slotToExpunge == staleSlot) slotToExpunge = i; //从交换之后,此时key为nul,正好从这里清理 cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); return; &#125; if (k == null &amp;&amp; slotToExpunge == staleSlot) slotToExpunge = i; //遇到第一个key为null的位置,记录下来 &#125; //运行到这里,说明没有遇到key相等的,则在slot处新建一个新的Entry,把key,value设置进去. tab[staleSlot].value = null; //方便GC tab[staleSlot] = new Entry(key, value); //如果还有key为null的Entry,则清理 if (slotToExpunge != staleSlot) 说明存在key为null的Entry,则清理 cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); &#125; slotToExpunge主要用来记录从前到后key为null的位置,方便清理 第1个for循环：我们向前找到key为null的位置，记录为slotToExpunge,这里是为了后面的清理过程，可以不关注了； 第2个for循环：我们从staleSlot起到下一个null为止，若是找到key和传入key相等的Entry，就给这个Entry赋新的value值，并且把它和staleSlot位置的Entry交换，然后调用CleanSomeSlots清理key为null的Entry。 若是一直没有key和传入key相等的Entry，那么就在staleSlot处新建一个Entry。函数最后再清理一遍空key的Entry。cleanSomeSlots这个函数是以log(n)的速度去发现key为null的点.如果找到则调用expungeStaleEntry取清除和再hash,它里面就是不断的折半查找. expungeStaleEntry(int staleSlot)1234567891011121314151617181920212223242526272829303132private int expungeStaleEntry(int staleSlot) &#123; Entry[] tab = table; int len = tab.length; // 把该位置设置为null tab[staleSlot].value = null; tab[staleSlot] = null; size--; // Rehash until we encounter null Entry e; int i; for (i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == null) &#123; //遇到key为null的,则设置为null,方便gc e.value = null; tab[i] = null; size--; &#125; else &#123; int h = k.threadLocalHashCode &amp; (len - 1); //如果有值,再hash if (h != i) &#123; tab[i] = null; while (tab[h] != null) h = nextIndex(h, len); tab[h] = e; &#125; &#125; &#125; return i;&#125; expungeStaleEntry的逻辑是: 先把该位置设置为null,方便GC 从当前位置顺着往下走,直到第一为null的Entry.在这过程中,如果遇到key为null,则把该位置的Entry设置为null,有利于GC. 如果key不为null,则把该元素重新hash(线性探测法) rehash1234567891011121314151617181920212223242526272829private void rehash() &#123; expungeStaleEntries(); //清除过时的Entry,这里只要是key为null,这调用expungeStaleEntry(int staleSlot),也就是上面这个方法 if (size &gt;= threshold - threshold / 4) //清理后,如果size还大于3/4的threshold,那么就扩容 resize(); &#125;private void resize() &#123; Entry[] oldTab = table; int oldLen = oldTab.length; int newLen = oldLen * 2; Entry[] newTab = new Entry[newLen]; //开辟一个数组大小是原来两倍大的数组 int count = 0; for (int j = 0; j &lt; oldLen; ++j) &#123; Entry e = oldTab[j]; if (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == null) &#123; e.value = null; // 帮助GC &#125; else &#123; //重新hash到新数组中 int h = k.threadLocalHashCode &amp; (newLen - 1); while (newTab[h] != null) h = nextIndex(h, newLen); newTab[h] = e; count++; &#125; &#125; &#125; rehash的逻辑是: 先尝试清除key为null的位置 再观察是否达到3/4的阈值,从而来扩容 扩容的逻辑是; 开辟一个长度是以前数组两倍的数组,重新hash,放入到新数组中. 这个过程中,如果遇到key为空,则把值赋值为null,方便GCremove1234567891011121314private void remove(ThreadLocal&lt;?&gt; key) &#123; Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; if (e.get() == key) &#123; e.clear(); //把引用设为null,方便GC expungeStaleEntry(i); //上面已经谈到 return; &#125; &#125; &#125; remove的处理逻辑是把应用设置为null,方便GC.然后在调用 expungeStaleEntry(i)去掉key为null的Entry,再hash. 5. 关于expungeStaleEntry中当key不为空,为什么要重新hash是因为,如果不重新hash,那么后来再取寻找的时候,遇到Null就会停止搜索,这就造成原本能够找到的,现在找不到.归根结底采用了链地址法. 6. 使用ThreadLocal的最佳实践我们发现无论是set,get还是remove方法，过程中key为null的Entry都会被擦除，那么Entry内的value也就没有强引用链，GC时就会被回收。那么怎么会存在内存泄露呢？但是以上的思路是假设你调用get或者set方法了，很多时候我们都没有调用过，所以最佳实践就是 1 .使用者需要手动调用remove函数，删除不再使用的ThreadLocal. 2 .还有尽量将ThreadLocal设置成private static的，这样ThreadLocal会尽量和线程本身一起消亡。 参考文章:ThreadLocal源码深度剖析]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP/2 新特性总结]]></title>
    <url>%2F2018%2F03%2F19%2FHTTP-2-%E6%96%B0%E7%89%B9%E6%80%A7%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[我在想了解HTTP/2的时候，查阅了很多资料，发现这篇很好，是外国的文章．我翻译过来，加入自己的一点理解． HTTP/2 更简单,高效,强大.它在传输层解决了以前我们HTTP1.x中一直存在的问题.使用它可以优化我们的应用.HTTP/2 的首要目标是通过完全的请求,响应多路复用,头部的压缩头部域来减小头部的体积,添加了请求优先级,服务端推送.为了支持这些特性,他需要大量的协议增加头部字段来支持,例如新的流量控制,差错处理,升级机制.而这些是每个web开发者都应该在他们的应用中用到的.HTTP/2并没有在应用中改变HTTP的语义,而是通过在客户端和服务端传输的数据格式(frame)和传输.它通过在新的二进制帧层控制整个过程以及隐藏复杂性,而这不需要改变原来有的东西就可以实现. 1. 设计和技术目标HTTP是因特网广泛普及和采纳的应用层协议.它的易于实现性同样有了对应用性能方面的影响.HTTP/1.x 需要开启多个连接来实现并发和减少潜在影响.HTTP/1.x 的头部没有压缩,造成不必要的网络拥塞.HTTP/1.x没有应用资源优先级,导致重要Tcp连接的糟糕使用.它的好处如下; HTTP/2 enables a more efficient use of network resources and a reduced perception of latency by introducing header field compression and allowing multiple concurrent exchanges on the same connection… Specifically, it allows interleaving of request and response messages on the same connection and uses an efficient coding for HTTP header fields. It also allows prioritization of requests, letting more important requests complete more quickly, further improving performance.The resulting protocol is more friendly to the network, because fewer TCP connections can be used in comparison to HTTP/1.x. This means less competition with other flows, and longer-lived connections, which in turn leads to better utilization of available network capacity. Finally, HTTP/2 also enables more efficient processing of messages through use of binary message framing.HTTP2.0并没有改变之前HTTP的语义,也就是说高层的Api并没有改变,它是在底层通过二进制frame来改变性能的. 2. 二进制帧层性能提升的核心在于二进制帧层.它指HTTP消息在客户端和服务端如何封装和传输.这一层指一个设计选择，它在socket接口之间采用一种更好的编码机制，而高层的Api提供给我们的应用。与HTTP1.x的采用的换行符分隔文本不同，HTTP/2 消息被分成很小的消息和frame,然后每个消息和frame用二进制编码。客户端和服务端都采用二进制编码和解码。HTTP/1.x 的客户端不能与只有HTTP/2的服务端通信。幸运的是，我们的应用还没意识到这些改变。客户端和服务端能够很好的处理这些帧。 ASCII 协议能够很容易的看出来和开始使用。然而它们是没有效率的，且很难正确设计：可选的空白，改变终止序列和其他的毛病使得协议很难区别出payload。虽然二进制协议用起来需要做很多工作，但是它们能表现出更好的性能。 3. 流,消息，帧接下来介绍二进制帧机制来明白数据如何在客户端和服务端交换的。流：已经建立的连接之间双向流动的字节，它能携带一个至多个消息。消息：一个完整的帧序列，它映射到逻辑的请求和响应消息。帧：在HTTP/2通信的最小单元。每个桢包括一个帧头，里面有个很小标志，来区别是属于哪个流。 所有的通信都建立在一个TCP连接上，可以传递大量的双向流通的流。 每个流都有独一无二的标志和优先级。 每个消息都是逻辑上的请求和相应消息。由一个或者多个帧组成。 来自不同流的帧可以通过帧头的标志来关联和组装起来。 这是 HTTP/2 协议提供高性能的基础。 4. 请求和响应的多路复用在HTTP/1.x中,用户想要多个并行的请求来提高性能,但是这样必须得使用多个TCP连接.这样的操作是属于HTTP/1.x 发送模型的直接序列.它能保证在每次连接中在一个时间点只有一个响应被发送出去.更糟糕的是,它使得队头阻塞和重要TCP连接的低效使用.在HTTP/2中,新的二进制帧层,解除了这个限制.使得所有的请求和响应多路复用.通过允许客户端和服务端把HTTP消息分解成独立的帧,交错传输,然后在另一端组装.图12-3显示了在一次连接中的多个流.客户端传输数据帧到服务端(Stream5).服务端传输交错的帧序列(Stream1,Stream3)到客户端.此时,同时存在并行的3个流.能够把HTTP消息分解成交错的帧,并在另一端组装它们是HTTP/2中一个非常重要的提高.事实上,它引起了一种波浪效应使得web技术的全栈在性能上有很大的提升.它有以下作用: 交错的多个并行的请求或者,而不需要阻塞. 使用一个连接传递所有的并行的请求和响应. 移除了HTTP/1.x中没有的必要的解决方法.例如级联文件,域分片. 淘汰没必要的潜在因素来降低页面载入的时间.提升可用网络容积的使用率. 新的二进制帧层解决了HTTP/1.X中头部阻塞的问题.在并行处理和传输的请求和响应不再需要多个连接.这使得我们的应用更简单,快捷和便宜. 5. 流的优先级.为了能方便流的传输顺序,HTTP/2.0提出,使每个流都有一个权重和依赖. 每个流的权重值在1~256之间 每个流可以详细给出对其他流的依赖 流权重和依赖的结合使客户端可以构造和通信一个优先级二叉树来表达它更想得到哪种响应.然后服务端可以按权重分配硬件资源(CPU,内存).在HTTP/2 ,一个流的依赖可以显式用其他流的标志来表达,如果省略了标志,则说明它的依赖是根流.一般来说,父流应该在它的依赖流之前分配资源,例如D应该是C之前被发送.依赖于同一父节点的应该按照他们的权重分配资源.例如A结点的权重为12,它的兄弟结点B的结点的权重为4.然后按比例分资源,A占12/16,B占4/16.如上面所述,流的依赖和权重提供了一种很好的表达式语言来表达资源的优先级.但是我们应该明白,,流的依赖和权重只是提供了一种传输偏好,而不是说一定是这样的比例. ##### 5.每个源一个连接HTTP/2.0的连接是持久的,每个源仅仅需要一个连接.大部分HTTP的传输是短的,并且突然的.然而TCP连接却适合长期存活的,批量的数据传输.通过利用相同的HTTP/2 连接,既能够充分利用TCP连接,也能减小整体协议的头部.更进一步来说,更少的连接内存的占用以及全连接路径的处理过程.向HTTP/2的转移不仅减少了网络潜在因素,更减少了操作代价. Tips:减少连接,同时也提高了HTTPS的性能,因为仅需要更少的TLS层的握手. 5. 流量控制流量控制是一种机制,用来阻止发送者发送大量的接收者不需要,或者没能力处理的数据.接收者可能会在重负下很繁忙,或者只愿意分配固定的资源给特定的流.例如,客户端可能以高的优先级请求大量的视频数据,然后用户暂停了视频,那么客户端现在想要停止或者减少服务端的传输来避免取和缓存没必要的数据.或者一个代理服务器连接有很快的下流,很慢的上流,同样的也要控制以多大的流速传输数据,从而匹配上流的速度,从而控制资源的使用. 这些需求可能让你想起了TCP流量控制,由于HTTP/2的那些流是在一个TCP的连接上.那么TCP连接不够细粒度,也没能提供应用级的API来控制单个流的传输.为了应对这种情况,HTTP/2提供了一系列的简单修筑块,来允许客户端和服务端实现他们自己的流级别的,连接级别的流量控制. 流量控制是有方向的.对于每个流和连接,每个接收者可以设置它想要窗口大小. 流量控制是基于信用的。每个接收者通告其初始连接和流量控制窗口（以字节为单位），只要发送者发送数据帧并通过接受者发送的WINDOW_UPDATE帧递增，该窗口就会减少。 流量控制不能禁用.当建立HTTP / 2连接时，客户端和服务器交换SETTINGS帧，这些帧设置双向流量控制窗口的大小。流量控制窗口的默认值设置为65,535字节，但接收方可以设置更大的最大窗口大小（2的31次方-1字节），并通过在接收到任何数据时发送WINDOW_UPDATE帧来维护它。 流量控制是逐跳的,而不是端到端的.也就是说,一个中介可以使用它控制资源的使用,从而根据自己的标准和启发式实现资源分配机制. HTTP / 2没有规定用于实现流量控制的任何特定算法。相反，它提供了简单的构建模块并将实现推迟到客户端和服务器，这可以用它来实现自定义策略来调节资源使用和分配，以及实现新的传输功能，这可能有助于提高Web应用程序真实性和感知性。 例如，应用程序层流控量制允许浏览器仅提取特定资源的一部分，通过将流量控制窗口降至零来暂停提取，然后稍后恢复 - 例如，获取预览或第一次浏览图像，显示图像并允许进行其他高优先级操作取来操作，并在关键资源完成加载后又开始取。 6.服务端推送HTTP / 2的另一个强大的新功能是服务器为单个客户端请求发送多个响应的能力。也就是说，除了对原始请求的响应之外，服务器还可以向客户端推送额外的资源（图12-5），而不需要客户端明确请求每一个资源！ HTTP / 2脱离了严格的请求 - 响应语义，并支持一对多和服务器启动的推送工作流程，在浏览器内部和外部打开全新的交互可能性。这是一个启动功能，对于我们如何考虑协议以及在何处以及如何使用协议，都会产生重要的长期影响。 为什么我们需要在浏览器中使用这种机制？一个典型的Web应用程序由几十个资源组成，所有这些资源都是客户端通过检查服务器提供的文档发现的。因此，为什么不消除额外的延迟并让服务器提前推送相关资源？服务器已经知道客户端需要哪些资源;这是服务器推动。事实上，如果您曾经通过数据URI将CSS，JavaScript或任何其他资产内联到一起（请参阅资源内联），那么您已经有了服务器推送的实践经验！通过手动将资源内联到文档中，实际上，我们将该资源推送到客户端，而无需等待客户端请求。通过HTTP / 2，我们可以获得相同的结果，但是具有额外的性能优势： 推送的资源可以由客户端缓存 推送的资源可以在不同的页面上重复使用 推送的资源可以与其他资源一起复用 推送的资源可以由服务器优先 推送的资源可以被客户拒绝 每个推送的资源都是一个流，与内联资源不同，它允许客户端对其进行单独复用，优先化和处理。由浏览器执行的唯一安全限制是推送资源必须遵守同源策略：服务器必须对提供的内容具有权限。 7. 头部压缩每个HTTP传输都包含一组描述传输资源及其属性的标题。在HTTP / 1.x中，此元数据始终以纯文本形式发送，并且每次传输的开销都会在任何位置增加500-800字节，如果使用HTTP Cookie，则会增加数千字节。为了减少这种开销并提高性能，HTTP / 2使用两种简单但强大的技术使用HPACK压缩格式(要了解这个算法,可以参考这篇文章https://imququ.com/post/header-compression-in-http2.html)来压缩请求和响应头元数据： 它允许通过静态霍夫曼编码对传输的头部字段进行编码，从而减少它们各自的传输大小。 它要求客户端和服务器都维护和更新先前看到的标题字段的索引列表（即，建立共享压缩上下文），然后将其用作参考以高效编码先前传输的值。 霍夫曼编码允许单个值在传输时被压缩，并且先前传输值的索引列表允许我们通过传输索引值来编码重复值（图12-6），索引值可用于有效地查找和重建完整头部键和值。作为进一步优化，HPACK压缩上下文由静态和动态表组成：静态表在规范中定义，并提供所有连接可能使用的常见HTTP头字段的列表（例如，有效头名称）;动态表最初是空的，并基于特定连接内的交换值进行更新。因此，通过对以前未见过的值使用静态霍夫曼编码，并将索引替换为已存在于客户端和服务端静态或动态表中的值的索引，可以减少每个请求的大小。 8. 二进制帧的简短介绍所有HTTP / 2改进的核心是新的二进制长度前缀成帧层。与以换行符分隔的纯文本HTTP / 1.x协议相比，二进制框架提供了更紧凑的表示形式，可以更高效地处理并更容易正确实现。一旦建立了HTTP / 2连接，客户端和服务器就通过交换帧来进行通信，这些帧用作协议内最小的通信单元。所有帧共享一个共同的9字节头（图12-7），其中包含帧的长度，类型，标志位字段和31位流标识符。 24位长度字段允许一个帧携带2的24次方数据字节。 8位类型字段确定帧的格式和语义。 8位标志字段传递帧类型特定的布尔标志。 1位保留字段始终设置为0。 31位流标识符唯一标识HTTP / 2流。 从技术上讲，长度字段允许每帧高达字节（〜16MB）的有效载荷。但是，HTTP / 2标准将DATA帧的默认最大有效负载大小设置为每帧字节（〜16KB），并允许客户端和服务器协商较高的值。更大并不总是更好：较小的帧大小能够实现高效的多路复用并将头部阻塞降至最低。 9. 分析二进制帧数据流掌握了不同帧类型的知识后，我们现在可以重新看下我们前面在请求和响应复用中遇到的图（图12-10）并分析HTTP / 2交换： 有三个流，ID设置为1,3和5。 所有三个流ID都是奇数;所有这三个都是客户端启动的流。(即发起方是客户端) 在这个交换中没有服务器启动（“推送”）流。(即服务端推送) 服务器正在为流1发送交错数据帧，这些数据帧携带应用程序响应客户端先前的请求。 服务器已经在数据帧之间为流3交错了HEADERS和DATA帧，以便实现流1响应多路复用！ 客户端正在传输数据流5的数据帧，这表明HEADERS帧已在先传输。 当然，上述分析基于实际HTTP / 2交换的简化表示，但它仍然说明了新协议的许多优点和特点. 参考文章:https://imququ.com/post/header-compression-in-http2.htmlhttps://hpbn.co/http2/#header-compression]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>HTTP/2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty权威指南读书笔记1：Java的I/O演进之路]]></title>
    <url>%2F2018%2F01%2F13%2FNetty%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B01%EF%BC%9AJava%E7%9A%84I-O%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF%2F</url>
    <content type="text"><![CDATA[1.1 用户空间以及内核空间概念针对linux操作系统而言，将最高的1G字节（从虚拟地址0xC0000000到0xFFFFFFFF），供内核使用，称为内核空间，而将较低的3G字节（从虚拟地址0x00000000到0xBFFFFFFF），供各个进程使用，称为用户空间。有了用户空间和内核空间，整个linux内部结构可以分为三部分，从最底层到最上层依次是：硬件–&gt;内核空间–&gt;用户空间。我们都知道，为了OS的安全性等的考虑，进程是无法直接操作I/O设备的，其必须通过系统调用请求内核来协助完成I/O动作，而内核会为每个I/O设备维护一个buffer。 整个请求过程为： 用户进程发起请求，内核接受到请求后，从I/O设备中获取数据到buffer中，再将buffer中的数据copy到用户进程的地址空间，该用户进程获取到数据后再响应客户端。 在整个请求过程中，数据输入至buffer需要时间，而从buffer复制数据至进程也需要时间。因此根据在这两段时间内等待方式的不同，I/O动作可以分为以下五种模式： 阻塞I/O (Blocking I/O) 非阻塞I/O (Non-Blocking I/O) I/O复用（I/O Multiplexing) 信号驱动的I/O (Signal Driven I/O) 异步I/O (Asynchrnous I/O) 2.1 阻塞I/O (Blocking I/O)&emsp;&emsp;在linux中，默认情况下所有的socket都是blocking，一个典型的读操作流程大概是这样： &emsp;&emsp;当用户进程调用了recvfrom这个系统调用，内核就开始了IO的第一个阶段：等待数据准备。对于network io来说，很多时候数据在一开始还没有到达（比如，还没有收到一个完整的UDP包），这个时候内核就要等待足够的数据到来。而在用户进程这边，整个进程会被阻塞。当内核一直等到数据准备好了，它就会将数据从内核中拷贝到用户内存，然后内核返回结果，用户进程才解除block的状态，重新运行起来。 所以，blocking IO的特点就是在IO执行的两个阶段都被block了。（整个过程一直是阻塞的） 2.2 非阻塞I/O (Non-Blocking I/O)&emsp;&emsp;linux下，可以通过设置socket使其变为non-blocking。当对一个non-blocking socket执行读操作时，流程是这个样子： &emsp;&emsp;当用户进程调用recvfrom时，系统不会阻塞用户进程，而是立刻返回一个ewouldblock错误，从用户进程角度讲 ，并不需要等待，而是马上就得到了一个结果（这个结果就是ewouldblock ）。用户进程判断标志是ewouldblock时，就知道数据还没准备好，于是它就可以去做其他的事了，于是它可以再次发送recvfrom，一旦内核中的数据准备好了。并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存，然后返回。 当一个应用程序在一个循环里对一个非阻塞调用recvfrom，我们称为轮询。应用程序不断轮询内核，看看是否已经准备好了某些操作。这通常是浪费CPU时间，但这种模式偶尔会遇到。 2.3 I/O复用（I/O Multiplexing)&emsp;&emsp;IO multiplexing这个词可能有点陌生，但是如果我说select，epoll，大概就都能明白了。有些地方也称这种IO方式为event driven IO。我们都知道，select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select/epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。它的流程如图： &emsp;&emsp;当用户进程调用了select，那么整个进程会被block，而同时，内核会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从内核拷贝到用户进程。 这个图和blocking IO的图其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个system call (select 和 recvfrom)，而blocking IO只调用了一个system call (recvfrom)。但是，用select的优势在于它可以同时处理多个connection。（多说一句。所以，如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。） 在IO multiplexing Model中，实际中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的process其实是一直被block的。只不过process是被select这个函数block，而不是被socket IO给block。 文件描述符fdLinux的内核将所有外部设备都可以看做一个文件来操作。那么我们对与外部设备的操作都可以看做对文件进行操作。我们对一个文件的读写，都通过调用内核提供的系统调用；内核给我们返回一个filede scriptor（fd,文件描述符）。而对一个socket的读写也会有相应的描述符，称为socketfd(socket描述符）。描述符就是一个数字，指向内核中一个结构体（文件路径，数据区，等一些属性）。那么我们的应用程序对文件的读写就通过对描述符的读写完成。 select基本原理：select 函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。调用后select函数会阻塞，直到有描述符就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以通过遍历fdset，来找到就绪的描述符。 缺点: 1、select最大的缺陷就是单个进程所打开的FD是有一定限制的，它由FDSETSIZE设置，32位机默认是1024个，64位机默认是2048。 一般来说这个数目和系统内存关系很大，”具体数目可以cat /proc/sys/fs/file-max察看”。32位机默认是1024个。64位机默认是2048. 2、对socket进行扫描时是线性扫描，即采用轮询的方法，效率较低。 当套接字比较多的时候，每次select()都要通过遍历FDSETSIZE个Socket来完成调度，不管哪个Socket是活跃的，都遍历一遍。这会浪费很多CPU时间。”如果能给套接字注册某个回调函数，当他们活跃时，自动完成相关操作，那就避免了轮询”，这正是epoll与kqueue做的。 3、需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大。 poll基本原理：poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。这个过程经历了多次无谓的遍历。 它没有最大连接数的限制，原因是它是基于链表来存储的，但是同样有一个缺点：1、大量的fd的数组被整体复制于用户态和内核地址空间之间，而不管这样的复制是不是有意义。 2 、poll还有一个特点是“水平触发”，如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd。 注意：从上面看，select和poll都需要在返回后，通过遍历文件描述符来获取已经就绪的socket。事实上，同时连接的大量客户端在一时刻可能只有很少的处于就绪状态，因此随着监视的描述符数量的增长，其效率也会线性下降。 epoll(事件驱动）epoll是在2.6内核中提出的，是之前的select和poll的增强版本。相对于select和poll来说，epoll更加灵活，没有描述符限制。epoll使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。 基本原理：epoll支持水平触发和边缘触发，最大的特点在于边缘触发，它只告诉进程哪些fd刚刚变为就绪态，并且只会通知一次。还有一个特点是，epoll使用“事件”的就绪通知方式，通过epollctl注册fd，一旦该fd就绪，内核就会采用类似callback的回调机制来激活该fd，epollwait便可以收到通知。 epoll的优点：1、没有最大并发连接的限制，能打开的FD的上限远大于1024（1G的内存上能监听约10万个端口）。 2、效率提升，不是轮询的方式，不会随着FD数目的增加效率下降。 只有活跃可用的FD才会调用callback函数；即Epoll最大的优点就在于它只管你“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，Epoll的效率就会远远高于select和poll。 3、内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递；即epoll使用mmap减少复制开销。 JDK1.5_update10版本使用epoll替代了传统的select/poll，极大的提升了NIO通信的性能。 备注：JDK NIO的BUG，例如臭名昭著的epoll bug，它会导致Selector空轮询，最终导致CPU 100%。官方声称在JDK1.6版本的update18修复了该问题，但是直到JDK1.7版本该问题仍旧存在，只不过该BUG发生概率降低了一些而已，它并没有被根本解决。这个可以在后续netty系列里面进行说明下。 信号驱动的I/O (Signal Driven I/O) 很明显可以看出用户进程不是阻塞的。首先用户进程建立SIGIO信号处理程序，并通过系统调用sigaction执行一个信号处理函数，这时用户进程便可以做其他的事了，一旦数据准备好，系统便为该进程生成一个SIGIO信号，去通知它数据已经准备好了，于是用户进程便调用recvfrom把数据从内核拷贝出来，并返回结果。 3.5 异步I/O一般来说，这些函数通过告诉内核启动操作并在整个操作（包括内核的数据到缓冲区的副本）完成时通知我们。这个模型和前面的信号驱动I/O模型的主要区别是，在信号驱动的I/O中，内核告诉我们何时可以启动I/O操作，但是异步I/O时，内核告诉我们何时I/O操作完成。 当用户进程向内核发起某个操作后，会立刻得到返回，并把所有的任务都交给内核去完成（包括将数据从内核拷贝到用户自己的缓冲区），内核完成之后，只需返回一个信号告诉用户进程已经完成就可以了。 5中I/O模型的对比 结果表明：前四个模型之间的主要区别是第一阶段，四个模型的第二阶段是一样的：过程受阻在调用recvfrom当数据从内核拷贝到用户缓冲区。然而，异步I/O处理两个阶段，与前四个不同。 从同步、异步，以及阻塞、非阻塞两个维度来划分来看： 参考文档匠心零度的公众号Netty权威指南第一章]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[红黑树的原理和常见操作]]></title>
    <url>%2F2018%2F01%2F13%2F%E7%BA%A2%E9%BB%91%E6%A0%91%E7%9A%84%E5%8E%9F%E7%90%86%E5%92%8C%E5%B8%B8%E8%A7%81%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[1. 概述在jdk1.8中，HashMap和ConcurrentHashMap中都采用了红黑树这一数据结构。即当链表达到一定的长度后，就把链表转化成红黑树。这其中主要利用了红黑树的良好性质，不管你节点怎样，他始终保持查找时间复杂度为O(logn)。这样的性质相对于链表在长度很长的时候有很大的优势。O(logn）&lt;O(lgn) 2. 红黑树的定义 每个结点要么是红的，要么是黑的。 根结点是黑的。 每个叶结点（叶结点即指树尾端NIL指针或NULL结点）是黑的。 如果一个结点是红的，那么它的俩个儿子都是黑的。 对于任一结点而言，其到叶结点树尾端NIL指针的每一条路径都包含相同数目的黑结点。一棵典型的红黑树如下： 3. 红黑树的插入在这里，默认你熟悉二叉查找树的结构，以及他的插入和删除操作。红黑树本质上是一棵二叉查找树。对红黑树的插入，我们先按二叉查找树去插入，然后对对树做调整，使其满足红黑树的五条定义。（这是因为你插入会破坏其中的规则）二叉查找树的插入伪代码如下：123456789101112131415161718RB-INSERT(T, z) 1 y ← nil[T] 2 x ← root[T] 3 while x ≠ nil[T] 4 do y ← x 5 if key[z] &lt; key[x] 6 then x ← left[x] 7 else x ← right[x] 8 p[z] ← y 9 if y = nil[T] 10 then root[T] ← z 11 else if key[z] &lt; key[y] 12 then left[y] ← z 13 else right[y] ← z 14 left[z] ← nil[T] 15 right[z] ← nil[T] 16 color[z] ← RED 17 RB-INSERT-FIXUP(T, z) 可以看出，RB-INSERT(T, z)前面的第1-13行代码基本就是二叉查找树的插入代码，然后第14-16行代码把z的左孩子、右孩子都赋为叶结点nil，再把z结点着为红色，最后为保证红黑性质在插入操作后依然保持，调用一个辅助程序RB-INSERT-FIXUP来对结点进行重新着色，并旋转。换言之 如果插入的是根结点，因为原树是空树，此情况只会违反性质2，所以直接把此结点涂为黑色。 如果插入的结点的父结点是黑色，由于此不会违反性质2和性质4，红黑树没有被破坏，所以此时也是什么也不做。 但当遇到下述3种情况时： 插入修复情况1：如果当前结点的父结点是红色且祖父结点的另一个子结点（叔叔结点）是红色 插入修复情况2：当前结点的父结点是红色,叔叔结点是黑色，当前结点是其父结点的右子 插入修复情况3：当前结点的父结点是红色,叔叔结点是黑色，当前结点是其父结点的左子 3.1 插入修复情况1：当前结点的父结点是红色且祖父结点的另一个子结点（叔叔结点）是红色。插入的伪代码如下：123456781 while color[p[z]] = RED 2 do if p[z] = left[p[p[z]]] 3 then y ← right[p[p[z]]] 4 if color[y] = RED 5 then color[p[z]] ← BLACK ▹ Case 1 6 color[y] ← BLACK ▹ Case 1 7 color[p[p[z]]] ← RED ▹ Case 1 8 z ← p[p[z]] ▹ Case 1 如下面两个调整前的图和调整之后的图做对比。其中4为新添加的点。它的父节点为红色，叔叔节点为红色。那么调整就是把4的叔叔节点变为黑色（8节点），4的祖父节点变为红色，把当前结点指向祖父结点，从新的当前结点重新开始算法（7节点变为N)。 3.2 插入修复情况2：当前结点的父结点是红色,叔叔结点是黑色，当前结点是其父结点的右子123 9 else if z = right[p[z]]10 then z ← p[z] ▹ Case 211 LEFT-ROTATE(T, z) ▹ Case 2 调整之前的图如3.1.2，经过调整后得到如下的图。过程是当前结点的父结点做为新的当前结点，以新当前结点为支点左旋. 3.3 插入修复情况3：当前结点的父结点是红色,叔叔结点是黑色，当前结点是其父结点的左子12312 color[p[z]] ← BLACK ▹ Case 313 color[p[p[z]]] ← RED ▹ Case 314 RIGHT-ROTATE(T, p[p[z]]) ▹ Case 3 调整过程是把父结点变为黑色，祖父结点变为红色，在祖父结点为支点右旋。最后，把根结点涂为黑色，整棵红黑树便重新恢复了平衡。调整之前的图如3.2.2，经过调整后得到下图。 3. 红黑树的删除在这里默认你熟悉二叉查找树的删除操作。 下面我们用一个分析技巧：我们从被删结点后来顶替它的那个结点开始调整，并认为它有额外的一重黑色。这里额外一重黑色是什么意思呢，我们不是把红黑树的结点加上除红与黑的另一种颜色，这里只是一种假设，我们认为我们当前指向它，因此空有额外一种黑色，可以认为它的黑色是从它的父结点被删除后继承给它的，它现在可以容纳两种颜色，如果它原来是红色，那么现在是红+黑，如果原来是黑色，那么它现在的颜色是黑+黑。有了这重额外的黑色，原红黑树性质5就能保持不变。现在只要恢复其它性质就可以了，做法还是尽量向根移动和穷举所有可能性。”–saturnman。如果是以下情况，恢复比较简单： 当前结点是红+黑色解法，直接把当前结点染成黑色，结束此时红黑树性质全部恢复。 当前结点是黑+黑且是根结点， 解法：什么都不做，结束。 下面4中特殊情况 删除修复情况1：当前结点是黑+黑且兄弟结点为红色(此时父结点和兄弟结点的子结点分为黑) 删除修复情况2：当前结点是黑加黑且兄弟是黑色且兄弟结点的两个子结点全为黑色 删除修复情况3：当前结点颜色是黑+黑，兄弟结点是黑色，兄弟的左子是红色，右子是黑色 删除修复情况4：当前结点颜色是黑-黑色，它的兄弟结点是黑色，但是兄弟结点的右子是红色，兄弟结点左子的颜色任意 4.1 删除修复情况1：当前结点是黑+黑且兄弟结点为红色(此时父结点和兄弟结点的子结点分为黑)。解法：把父结点染成红色，把兄弟结点染成黑色，之后重新进入算法（我们只讨论当前结点是其父结点左孩子时的情况）。此变换后原红黑树性质5不变，而把问题转化为兄弟结点为黑色的情况(注：变化前，原本就未违反性质5，只是为了把问题转化为兄弟结点为黑色的情况)。 4.2 删除修复情况2：当前结点是黑加黑且兄弟是黑色且兄弟结点的两个子结点全为黑色。 解法：把当前结点和兄弟结点中抽取一重黑色追加到父结点上，把父结点当成新的当前结点，重新进入算法。（此变换后性质5不变）。伪代码如下。1234//调用RB-DELETE-FIXUP(T, x) 的9-11行代码9 if color[left[w]] = BLACK and color[right[w]] = BLACK10 then color[w] ← RED ▹ Case 211 x p[x] ▹ Case 2 4.3 删除修复情况3：当前结点颜色是黑+黑，兄弟结点是黑色，兄弟的左子是红色，右子是黑色。解法：把兄弟结点染红，兄弟左子结点染黑，之后再在兄弟结点为支点解右旋，之后重新进入算法。此是把当前的情况转化为情况4，而性质5得以保持。伪代码如下123456//调用RB-DELETE-FIXUP(T, x) 的第12-16行代码12 else if color[right[w]] = BLACK13 then color[left[w]] ← BLACK ▹ Case 314 color[w] ← RED ▹ Case 315 RIGHT-ROTATE(T, w) ▹ Case 316 w ← right[p[x]] ▹ Case 3 4.4 删除修复情况4：当前结点颜色是黑-黑色，它的兄弟结点是黑色，但是兄弟结点的右子是红色，兄弟结点左子的颜色任意。解法：把兄弟结点染成当前结点父结点的颜色，把当前结点父结点染成黑色，兄弟结点右子染成黑色，之后以当前结点的父结点为支点进行左旋，此时算法结束，红黑树所有性质调整正确。代码如下123456//调用RB-DELETE-FIXUP(T, x) 的第17-21行代码17 color[w] ← color[p[x]] ▹ Case 418 color[p[x]] ← BLACK ▹ Case 419 color[right[w]] ← BLACK ▹ Case 420 LEFT-ROTATE(T, p[x]) ▹ Case 421 x ← root[T] ▹ Case 4 以上就是红黑树的结构和性质，对于面试和源码的理解很有帮助。 参考文章：教你透彻了解红黑树]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>红黑树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jdk1.8 HashMap源码分析]]></title>
    <url>%2F2018%2F01%2F12%2FJdk1-8-HashMap%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[1. 概述平常我们开发中，可能用的最多的容器就是HashMap。我们来看下HashMap的结构如下图。它是由一个Node数组，每个数组元素又是有一个链表构成。接下来我们结合源码来分析下put(),get(),resize()者三个常见的操作。 2. 类成员变量的认识123456789static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // HashMap初始的bucket16.必须是2的n次幂，原因在后面会涉及到static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; //最大容量static final float DEFAULT_LOAD_FACTOR = 0.75f; //负载因子，估计整个bucket冲突，当到达bucket*0.75容量时，会引起扩容static final int TREEIFY_THRESHOLD = 8; //当链表长度大于这个值时，会转变成红黑树static final int UNTREEIFY_THRESHOLD = 6; //当树的节点低于这个值时会转变成链表 关于红黑树的介绍，参见我的下篇文章，红黑树的原理及常见的操作3. put()函数的解析put()添加操作的过程如下。 对key的hashCode()做hash，然后再计算index（求余）; 如果没碰撞直接放到bucket里； 如果碰撞了，以链表的形式存在buckets后； 如果碰撞导致链表过长(大于等于TREEIFY_THRESHOLD)，就把链表转换成红黑树； 如果节点已经存在就替换old value(保证key的唯一性) 如果bucket满了(超过load factor*current capacity)，就要resize。其他的解释都在源码中标注。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public V put(K key, V value) &#123; //对key的hashcode做hash return putVal(hash(key), key, value, false, true); &#125;//onlyIfAbsent为true时，相同的key不会改变替换值。这里的为false，会替换//evict表示模式，为fasle表示处于bucket处于创建阶段。这里用true指创建完了。 final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) //若为null,则创建bucket n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) //若bucket那个位置为null,则创建新的Node节点 tab[i] = newNode(hash, key, value, null); //表示bucket不为null else &#123; Node&lt;K,V&gt; e; K k; //key存在 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //若原来为TreeNode,则插入到红黑树种中 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); //若原来为链表 else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; //写入，若原来有值，则替换 if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; //若超过当前容量大小超过capacity*0.75，则会引起扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; &#125; 注意这里采用的二次hash()操作,不是直接对hashcode再hash。123456//hashcode的低16位和高16位做异或操作static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); &#125; 之所以这样hash，是采用key的hashcode的低16位和高16位做异或操作。这样的好处在于避免hash冲突。否则，它只取低16位，与高位无关，那么它有可能会hash冲突严重。另外，如果还有更严重的冲突，那么可以采用红黑树来解决，事实上Jdk1.8 HashMap也是采用的这样的思想。 Improve the performance of java.util.HashMap under high hash-collision conditions by using balanced trees rather than linked lists to store map entries. Implement the same improvement in the LinkedHashMap class. 4. get()的解析get()相对来说就非常简单了，过程如下。 bucket里的第一个节点，直接命中； 如果有冲突，则通过key.equals(k)去查找对应的entry 若为树，则在树中通过key.equals(k)查找，O(logn)； 若为链表，则在链表中通过key.equals(k)查找，O(n)。12345678910111213141516171819202122232425262728public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; &#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; //这个if判断bucket是否存在 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; //检查第一个Node（bucket中第一个节点）是否是要查找的。 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; //红黑树的查找key if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; //遍历链表，寻找key相同 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null; &#125; (n - 1) &amp; hash就是一个求索引，即求Node数组中的下标。这样的操作是，当我们的n(表示capacity时)取2的幂的时候，例如n取16，那么n-1=15（二进制表示1111）与hash做与操作的时候相当于取余，这样做比直接取余更高效。 5. reSize()的解析 当put时，如果发现目前的bucket占用程度已经超过了Load Factor所希望的比例，那么就会发生resize。在resize的过程，简单的说就是把bucket扩充为2倍，之后重新计算index，把节点再放到新的bucket中。 然而又因为我们使用的是2次幂的扩展(指长度扩为原来2倍)，所以，元素的位置要么是在原位置，要么是在(原位置+旧capacity)的位置。怎么理解呢？例如我们从16扩展为32时，具体的变化如下所示： 这个设计确实非常的巧妙，既省去了重新计算hash值的时间，而且同时，由于新增的1bit是0还是1可以认为是随机的，因此resize的过程，均匀的把之前的冲突的节点分散到新的bucket了。因此元素在重新计算hash之后，因为n变为2倍，那么n-1的mask范围在高位多1bit(红色)，因此新的index就会发生这样的变化： 因此，我们在扩充HashMap的时候，不需要重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”。可以看看下图为16扩充为32的resize示意图： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; //旧的hashMap容量已经达到最大值，那么最新的也只能是最大值 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; //如果原来存在旧的容量存在，那么新分配的就是旧的两倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125;//旧的容量oldThreshold已经存在，但是没分配容量。那么久新的容量=oldThreshold else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; //两个变量都没有初始化 else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125;//如果初始化的oldThreshold为0，则重新取整 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order //尾插法把节点插入新分配的bucket中。不带头节点的 Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab; &#125; 参考文章： Java HashMap工作原理及实现 HashMap1.8源码解读 深入浅出ConcurrentHashMap1.8]]></content>
      <categories>
        <category>Java源码分析</category>
      </categories>
      <tags>
        <tag>HashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自定义注解实现Restful接口版本管理]]></title>
    <url>%2F2017%2F12%2F02%2F%E8%87%AA%E5%AE%9A%E4%B9%89%E6%B3%A8%E8%A7%A3%E5%AE%9E%E7%8E%B0Restful%E6%8E%A5%E5%8F%A3%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;在我们的日常开发中，需求总是变化的。对于某个接口，随着需求的升级，也面临里面逻辑的变化。例如，对于/v1/hello,/v2/hello 两个请求，若存在相应的映射，则对应入座。否则都映射到最新的接口上。则映射到最新的接口上。此时，我们又想保持以前的接口还保留，那么我们此时需要做的事，把对接口的请求都映射到最新的接口上，而原来的接口请求还是映射原来的接口上。我在这里介绍用自定义注解的形式，在@RequestMapping()的映射原理上做文章。 自定义注解1234567@Target(&#123;ElementType.METHOD, ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Mappingpublic @interface ApiVersion &#123; int value();&#125; &emsp;&emsp;就是定义一个简单的注解@ApiVersion，这个注解可以在类上和方法上都可以应用。 注解的识别12345678910111213141516171819public class CustomRequestMappingHandlerMapping extends RequestMappingHandlerMapping &#123; @Override // ① protected RequestCondition&lt;ApiVesrsionCondition&gt; getCustomTypeCondition(Class&lt;?&gt; handlerType) &#123; ApiVersion apiVersion = AnnotationUtils.findAnnotation(handlerType, ApiVersion.class); return createCondition(apiVersion); &#125; @Override //② protected RequestCondition&lt;ApiVesrsionCondition&gt; getCustomMethodCondition(Method method) &#123; ApiVersion apiVersion = AnnotationUtils.findAnnotation(method, ApiVersion.class); return createCondition(apiVersion); &#125; //③ 实例化RequestCondition private RequestCondition&lt;ApiVesrsionCondition&gt; createCondition(ApiVersion apiVersion) &#123; return apiVersion == null ? null : new ApiVesrsionCondition(apiVersion.value()); &#125;&#125; &emsp;&emsp;我们知道，光定义注解是没什么用的，重要的是我们识别到注解，做相应的事。RequestMappingHandlerMapping类是与 @RequestMapping相关的，它定义映射的规则。即满足怎样的条件则映射到那个接口上。 &emsp;&emsp;①处构建类级的映射要求，AnnotationUtils.findAnnotation根据在类上面的注解实例化一个注解类。然后构造RequestCondition。 &emsp;&emsp;②处构建类级的映射要求，AnnotationUtils.findAnnotation根据在方法上面的注解实例化一个注解类。然后构造RequestCondition。AnnotationUtils.findAnnotation是用到Spring的工具类，根据标注的注解识别注解。很方便，比通过反射的方式来找到注解要方便。 自定义条件类12345678910111213141516171819202122232425262728293031323334public class ApiVesrsionCondition implements RequestCondition&lt;ApiVesrsionCondition&gt; &#123; // 路径中版本的前缀， 这里用 /v[1-9]/的形式 private final static Pattern VERSION_PREFIX_PATTERN = Pattern.compile("v(\\d+)/"); private int apiVersion; public ApiVesrsionCondition(int apiVersion)&#123; this.apiVersion = apiVersion; &#125; //将不同的筛选条件合并,这里采用的覆盖，即后来的规则生效 public ApiVesrsionCondition combine(ApiVesrsionCondition other) &#123; return new ApiVesrsionCondition(other.getApiVersion()); &#125; //根据request查找匹配到的筛选条件 public ApiVesrsionCondition getMatchingCondition(HttpServletRequest request) &#123; System.out.println(request.getRequestURI()); Matcher m = VERSION_PREFIX_PATTERN.matcher(request.getRequestURI()); if(m.find())&#123; Integer version = Integer.valueOf(m.group(1)); if(version &gt;= this.apiVersion) // 如果请求的版本号大于配置版本号， 则满足，即与请求的 return this; &#125; return null; &#125; //实现不同条件类的比较，从而实现优先级排序 public int compareTo(ApiVesrsionCondition other, HttpServletRequest request) &#123; return other.getApiVersion() - this.apiVersion; &#125; public int getApiVersion() &#123; return apiVersion; &#125;&#125; &emsp;&emsp;getMatchingCondition()利用正则表达式把请求路径中的/v1/hello中的1（版本号）找出来，然后返回与大于等于1的条件类。那么@RequestMapping则路由到产生该条件类的方法下。 测试123456789101112131415161718192021222324252627282930313233343536@RequestMapping("/&#123;version&#125;/")@Controllerpublic class VersionController &#123; @RequestMapping("hello") @ApiVersion(1) @ResponseBody public String hello()&#123; System.out.println("haha1.........."); return "hello version1"; &#125; @RequestMapping("hello") @ApiVersion(2) @ResponseBody public String hello2()&#123; System.out.println("haha2........."); return "hello version2"; &#125; @RequestMapping("hello") @ResponseBody @ApiVersion(5) public String hello5()&#123; System.out.println("haha5........."); return "hello version5"; &#125; @RequestMapping("test") @ResponseBody public String test()&#123; return "test"; &#125;&#125; &emsp;&emsp;每个方法上都用 @ApiVersion()注解啦。当在浏览器输入http://localhost:8761/v2/hello 则跳到hello2()方法中执行。当在浏览器输入http://localhost:8761/v5/hello 则跳到hello5()中执行，因为比5大的都调到最新hello5()执行。]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring boot构建自定义的starter]]></title>
    <url>%2F2017%2F11%2F04%2FSpring-boot%E6%9E%84%E5%BB%BA%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9A%84starter%2F</url>
    <content type="text"><![CDATA[在我们日常用springboot的开发过程中，经常会遇到使用如下的一个类来代表程序的入口类。即123456@SpringBootApplicationpublic class App &#123; public static void main(String[] args) &#123; SpringApplication.run(App.class, args); &#125;&#125; 包括我自己，我平常在开发的过程中，并没有去重点关注spring boot的运行原理，大家都是约定俗成的这么去使用。接下的过程中，将会结合源码简单的分析下springboot运行原理。 一.Springboot 自动配置原理分析 @SpringBootApplication注解@SpringBootApplication是一个复合注解，它包括@SpringBootConfiguration，@EnableAutoConfiguration，@ComponentScan三个注解。其中最关键的莫过@EnableAutoConfiguration这个注解。在它的源码中加入了这样一个注解@Import({EnableAutoConfigurationImportSelector.class})，EnableAutoConfigurationImportSelector,它使用SpringFactoriesLoader. loadFactoryNames方法来扫描META-INF/spring.factories文件，此文件中声明了有哪些自动配置。源码如下（我挑选出重要的一部分）1234567891011121314151617181920public static final String FACTORIES_RESOURCE_LOCATION = "META-INF/spring.factories";public static List&lt;String&gt; loadFactoryNames(Class&lt;?&gt; factoryClass, ClassLoader classLoader) &#123; String factoryClassName = factoryClass.getName(); try &#123; Enumeration&lt;URL&gt; urls = (classLoader != null ? classLoader.getResources(FACTORIES_RESOURCE_LOCATION) : ClassLoader.getSystemResources(FACTORIES_RESOURCE_LOCATION)); List&lt;String&gt; result = new ArrayList&lt;String&gt;(); while (urls.hasMoreElements()) &#123; URL url = urls.nextElement(); Properties properties = PropertiesLoaderUtils.loadProperties(new UrlResource(url)); String factoryClassNames = properties.getProperty(factoryClassName); result.addAll(Arrays.asList(StringUtils.commaDelimitedListToStringArray(factoryClassNames))); &#125; return result; &#125; catch (IOException ex) &#123; throw new IllegalArgumentException("Unable to load [" + factoryClass.getName() + "] factories from location [" + FACTORIES_RESOURCE_LOCATION + "]", ex); &#125; &#125; 我随便查看spring-boot-autoconfigure-1.5.3.RELEASE.jar中的spring.factories,有如下的自动配置。123456# Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\org.springframework.boot.autoconfigure.amqp.RabbitAutoConfiguration,\org.springframework.boot.autoconfigure.batch.BatchAutoConfiguration,\ 上述spring.factories对应key为org.springframework.boot.autoconfigure.EnableAutoConfiguration的值即为启动时候需要自动配置的类。 二. 实现自定义的starter 首先定义一个基本的对象类，用来接收application.properties里面特定字段的值。12345678910111213@ConfigurationProperties(prefix = "hello")public class HelloServiceProperties &#123; private static final String MSG="world"; private String msg=MSG; public String getMsg() &#123; return msg; &#125; public void setMsg(String msg) &#123; this.msg = msg; &#125;&#125; @ConfigurationProperties(prefix = &quot;hello&quot;)是类型安全的属性获取。在application.properties 中通过hello.msg来设置，如果不设置默认就是“word”。 定义条件类（根据此类的存在与否来创建这个类的Bean，这个类可以是第三方类库的类）。 123456789public class HelloService &#123; private String msg; public String sayHello()&#123; return msg; &#125; public void setMsg(String msg)&#123; this.msg=msg; &#125;&#125; 自动配置类1234567891011121314151617@Configuration //1@EnableConfigurationProperties(HelloServiceProperties.class)//2@ConditionalOnClass(HelloService.class) //3@ConditionalOnProperty(prefix = "hello",value = "enabled",matchIfMissing = true) //4public class HelloServiceAutoConfiguration &#123; @Autowired private HelloServiceProperties helloServiceProperties; @Bean @ConditionalOnMissingBean(HelloService.class) //5 public HelloService helloService()&#123; HelloService helloService=new HelloService(); helloService.setMsg(helloServiceProperties.getMsg()); return helloService; &#125;&#125; @Configuration 它告知 Spring 容器这个类是一个拥有 bean 定义和依赖项的配置类。 @EnableConfigurationProperties的bean可以以标准方式被注册(例如使用 @Bean 方法),即我定义HelloServiceProperties可以作为标准的Bean被容器管理。 @ConditionalOnClass表示该类在类路径下存在，自动配置该类下的Bean。 @ConditionalOnProperty当指定的属性等于指定的值的情况下加载当前配置类，在这里如果matchIfMissing如果为false，则在application.properties中必须存在hello.enable(且不能为false) @ConditionalOnMissingBean()表示指定的bean不在容器中，则重新新建@Bean注解的类，并交给容器管理。 配置好之后，我们还需要在src\main\resources下新建文件夹WEB-INF，再新建文件spring.factories里面的内容如下12org.springframework.boot.autoconfigure.EnableAutoConfiguration=\com.springboot.mystartertool.HelloServiceAutoConfiguration 里面指定的类是上面自定义的那个配置类HelloServiceAutoConfiguration 定义spring.factories的原因是因为@EnableAutoConfiguration会扫描jar包下所有spring.factories文件，从而构造自动配置类。我们使用的时候使用@Autowired注入就行。 在以上工作完成后，我们执行如下命令1mvn clean install 就将项目打包到本地maven仓库中，有条件的可以安装的到私服中。 三. 应用自定义starter 首先引入自定义的starter的jar包1234567891011 &lt;!--引入我的start--&gt; &lt;dependency&gt; &lt;groupId&gt;com.maskwang&lt;/groupId&gt; &lt;artifactId&gt;Springboot-mystart&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt;``` 2. 当我们在`application.properties`配置如下 ```Groovyhello.msg=maskwang 我们就可以使用自定义的starter啦。 123456789@RestControllerpublic class HelloController &#123; @Autowired HelloService helloService; @RequestMapping("/hello") public String hello() &#123; return helloService.sayHello(); &#125;&#125; 由于我们没有自定义HelloService，所以会配置类会发挥作用，新建一个HelloService,并把里面的msg设置成”maskwang”。没有配置msg，则会采用默认的。结果如下 参考文献： 使用 Java 配置进行 Spring bean 管理 Spring boot实战（汪云飞著）github地址]]></content>
      <categories>
        <category>Springboot</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>Springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HeadFirst设计模式4-工厂模式]]></title>
    <url>%2F2017%2F11%2F03%2FHeadFirst%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F4-%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[在我平常的工作中我们往往会写下如下的代码。1234567891011public Pizza orderPizza(String type) &#123; Pizza pizza = new Pizza(); //以下是变化的部分 if (type.equals("chesss")) &#123; pizza = new ChessPizza(); &#125; else if (type.equals("clam")) &#123; pizza = new CalmPizza(); &#125; pizza.bake(); return pizza; &#125; 以上代码的问题在于我们要增加种类的时候，需要打开这段代码进行修改。这样造成系统难以维护，也更容易犯错。我们对拓展开放，对修改关闭。通常这种情况下，应该抽象出变化的部分。 2.如何实现工厂模式。 我们首先实现一个简单工厂模式 抽象出变化的部分，就是工厂 1234567891011public class SimplePIizzaFactory &#123; public Pizza createPizza(String type) &#123; Pizza pizza = null; if (type.equals("ChessPizza")) &#123; pizza = new ChessPizza(); &#125; else if (type.equals("CalmPizza")) &#123; pizza = new CalmPizza(); &#125; return pizza; &#125;&#125; 调用的时候只需要用简单工厂生成就行 12345678910111213public class PizzaStroe &#123; SimplePIizzaFactory simplePIizzaFactory; public PizzaStroe(SimplePIizzaFactory simplePIizzaFactory) &#123; this.simplePIizzaFactory = simplePIizzaFactory; &#125; public Pizza orderPizza(String type) &#123; Pizza pizza =simplePIizzaFactory.createPizza(type); pizza.bake(); return pizza; &#125;&#125; 上面这样做的好处在于抽象出变化的部分，供其他部分调用 。另外，当我们需要修改的时候，只需要修改工厂类，其他的部分就不需要变动。 工厂模式（真正意义上的工厂模式） 工厂方法模式定义了一个创建对象的接口，但由子类决定要实例化的类是哪一个。工厂方法让类把实例化推迟到子类。 定义一个基本的工厂基类和它的子工厂类12345678910111213141516171819202122232425262728293031323334//定义抽象的Pizza类public abstract class Pizza &#123; public String name; public ArrayList&lt;String&gt; ingredent=new ArrayList&lt;&gt;(); void prepare()&#123; System.out.println("Prepare: "+name); for(int i=0;i&lt;ingredent.size();i++)&#123; System.out.print(ingredent.get(i)+" "); &#125; &#125; void bake()&#123; System.out.println("Pizza is baking"); &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public ArrayList&lt;String&gt; getIngredent() &#123; return ingredent; &#125; public void setIngredent(ArrayList&lt;String&gt; ingredent) &#123; this.ingredent = ingredent; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142public abstract class PizzaStroe &#123; public Pizza orderPizza(String type) &#123; //不用管子类是什么 Pizza pizza = createPizza(type); pizza.bake(); return pizza; &#125; //定义抽象方法，由子类来实现 public abstract Pizza createPizza(String type);&#125;//武汉的工厂类，生产出武汉style的Pizzapublic class WuhanPizzaStore extends PizzaStroe &#123; @Override public Pizza createPizza(String type) &#123; Pizza pizza = null; if (type.equals("CalmPizza")) &#123; pizza = new CalmPizza(); pizza.ingredent.add("WuhanStyle"); &#125; else if (type.equals("ChessPizza")) &#123; pizza = new ChessPizza(); pizza.ingredent.add("WuhanStyle"); &#125; return pizza; &#125;&#125;//北京的工厂类，生产出北京style的Pizzapublic class BeijingPizzaStore extends PizzaStroe &#123; @Override public Pizza createPizza(String type) &#123; Pizza pizza = null; if (type.equals("CalmPizza")) &#123; pizza = new CalmPizza(); pizza.ingredent.add("BeijingStyle"); &#125; else if (type.equals("ChessPizza")) &#123; pizza = new ChessPizza(); pizza.ingredent.add("BeijingStyle"); &#125; return pizza; &#125;&#125; 当我们需要Pizza的时候，只需要用那个工厂类就可以构造出那种风格的Pizza1234567891011public class PizzaTest &#123; public static void main(String[] args) &#123; PizzaStroe beijingPizzaStore=new BeijingPizzaStore(); PizzaStroe wuhanPizzaStore=new WuhanPizzaStore(); Pizza pizza1=beijingPizzaStore.orderPizza("CalmPizza"); Pizza pizza2=wuhanPizzaStore.orderPizza("CalmPizza"); System.out.println(pizza1.getName()); System.out.println(pizza2.getName()); &#125;&#125; 来看下类图的关系 &emsp;&emsp;简单工厂与工厂方法的区别：简单工厂把全部的事情在一个地方都处理完了，然而工厂方法却是创建一个框架，让子类决定如何实现。简单工厂的做法，可以将对象的创建封装起来，但是简单工厂不具备工厂方法的弹性，因为简单工厂不能变更正在创建的产品。 抽象工厂模式首先给出定义 抽象工厂模式 提供一个接口，用于创建相关或依赖对象的家族，而不需要明确指定具体类 首先我们定义抽象接口1234public interface PropertyFactory &#123; public String getName(); public ArrayList&lt;String&gt; getIngredent();&#125; 在实际的场合中，抽象接口里面的抽象方法都是返回某个想要创建的抽象类，我这里比较简单，直接返回字符串和集合。之所以称为抽象工厂，我们从这里就可以看出来。通过抽象的方法，返回你希望得到的类的基类。 我们构造抽象工厂类的实现类12345678910111213141516171819202122232425262728public class CalmPropertyFactory implements PropertyFactory &#123; @Override public String getName() &#123; return "NewCalmPizza"; &#125; @Override public ArrayList&lt;String&gt; getIngredent() &#123; ArrayList&lt;String&gt; arrayList=new ArrayList&lt;&gt;(); arrayList.add("Newcalm"); return arrayList; &#125;&#125;public class ChessPropertyFactory implements PropertyFactory &#123; @Override public String getName() &#123; return "NewChessPizza"; &#125; @Override public ArrayList&lt;String&gt; getIngredent() &#123; ArrayList&lt;String&gt; arrayList = new ArrayList&lt;&gt;(); arrayList.add("Newchess"); return arrayList; &#125;&#125; 那么此时的Pizza的子类应该如此构造12345678public class CalmPizza extends Pizza &#123; PropertyFactory propertyFactory; public CalmPizza(PropertyFactory propertyFactory) &#123; this.propertyFactory=propertyFactory; name=propertyFactory.getName(); ingredent=propertyFactory.getIngredent(); &#125;&#125; 直接用对应的原料工厂来构造。来看下类图。 个人总结（conclusion)&emsp;&emsp;通过以上的描述，我们很容易明白工厂模式，也很容易区分简单工厂和工厂模式的区别（即构造类是在一个工厂类里面统一构造，还是通过子类的工厂方法来构造）。但是令人迷惑的是工厂模式与抽象工厂模式有什么区别。区别如下： 抽象工厂的每个方法实际上看起来都像是工厂方法，每个方法都被声明成抽象。而子类的方法来覆盖这些方法来创建某些对象。注意到，这里的子类是想要构造类的成分，就像我上面的写的name和ingredent成员。Pizza的子类只需要依赖依赖这些成分工厂类，例如ChessPropertyFactory ，就能构造出对象。重点突出抽象，是因为它有一个总的抽象接口，实现它的子类负责构造对象的成分，总而构成对象。]]></content>
      <categories>
        <category>DesignPattern</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HeadFirst设计模式3-装饰者模式]]></title>
    <url>%2F2017%2F10%2F15%2FHeadFirst%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F3-%E8%A3%85%E9%A5%B0%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[在我们的工作中，往往会这样的需求，就是动态地将责任附加到对象上，来达到拓展对象功能的目的。例如，对于做饼这件事来说，往往在做好一个饼之后，会有加糖，加盐，加鸡蛋这样类似的客户需求，不同的需求价格当然不同。我们通常的做法创建基类（Cake），然后让其他的子类继承它，试想下，如果如果有很多的类，岂不是会造成类爆炸，新出一款新的饼，就会构造一个类，计算不同的价格。而装饰者模式应用在这上面就非常的好。你想加糖，那我在外面包装一层，把额外的价格加上去。以后如果有几种配料的叠加，不用创造新的类，由原来的子类通过装饰者模式包装起来就行。 2. 如何实现装饰者模式how) 定义一个饼的基类，其他的饼的种类继承它。12345678910public abstract class Cake &#123; public String message="CAKE"; public float cost; public String getMessage()&#123; return message; &#125; //每个实现类自己实现 public abstract float getCost();&#125; 油饼，和糖饼分别实现饼1234567891011121314151617181920212223public class BatterCake extends Cake &#123; public BatterCake() &#123; message="batterCake"; &#125; @Override public float getCost() &#123; this.cost=1.2f; return cost; &#125;&#125;public class OilCake extends Cake&#123; //饼的实现类，油饼 public OilCake() &#123; message="oilCake"; &#125; @Override public float getCost() &#123; this.cost=1.5f; return cost; &#125;&#125; 可以分别加糖或者加盐，因此先来个装饰器接口 123public abstract class CakeDecorator extends Cake &#123; &#125; &emsp;&emsp;分别实现通过装饰器加糖和加盐 12345678910111213141516171819202122/** * Created by maskwang on 2017/10/15 0015. * 饼加盐 */public class SaltDecorator extends CakeDecorator&#123; Cake cake; public SaltDecorator(Cake cake) &#123; this.cake = cake; &#125; @Override public String getMessage() &#123; return cake.getMessage()+" with salt "; &#125; @Override public float getCost() &#123; return cake.getCost()+0.3f; &#125;&#125; 1234567891011121314151617public class SugerDecorator extends CakeDecorator &#123; Cake cake; public SugerDecorator(Cake cake) &#123; this.cake = cake; &#125; @Override public String getMessage() &#123; return cake.getMessage()+" with suger "; &#125; @Override public float getCost() &#123; return cake.getCost()+0.2f; //饼的钱+糖的钱 &#125;&#125; 测试一下通过装饰器既加糖又加盐123456789public class Test &#123; public static void main(String[] args) &#123; Cake cake = new OilCake(); cake = new SaltDecorator(cake); cake=new SugerDecorator(cake); System.out.println(cake.getMessage()); System.out.println(cake.getCost()); &#125;&#125; 结果如下： &emsp;&emsp;这里解释一下，最后的2.0如何出来，构造出OilCake，cost就是1.5， cake = new SaltDecorator(cake)，那么cost就是1.8。cake=new SugerDecorator(cake)，那么就是2.0。 我们常见到的IO包下，就运用到装饰者模式，例如BufferedInputStream,DataInputStream等。也可以实现一个装饰器，把字母转化成小写。如下：12345678910111213141516171819202122232425262728293031package com.designpattern.decoratorpattern;import java.io.FilterInputStream;import java.io.IOException;import java.io.InputStream;/** * Created by maskwang on 2017/10/15 0015. */public class UperCaseInputStream extends FilterInputStream &#123; public UperCaseInputStream(InputStream in) &#123; super(in); &#125; @Override public int read() throws IOException &#123; int c=super.read(); return (c==-1?c:Character.toUpperCase((char)c)); &#125; @Override public int read(byte[] b, int off, int len) throws IOException &#123; int result=super.read(b,off,len); for(int i=off;i&lt;off+result;i++)&#123; b[i]=(byte)Character.toUpperCase((char)b[i]); &#125; return result; &#125;&#125; 测试IO装饰类1234567891011121314151617 public static void main(String[] args) throws IOException &#123;// Cake cake = new OilCake();// cake = new SaltDecorator(cake);// cake=new SugerDecorator(cake);// System.out.println(cake.getMessage());// System.out.println(cake.getCost()); int c; try &#123; InputStream in=new UperCaseInputStream(new BufferedInputStream(new FileInputStream("E:\\test.txt"))); while ((c=in.read())&gt;0) System.out.println((char)(c)); &#125;catch (IOException e)&#123; e.printStackTrace(); &#125; &#125;![Uploading image_647020.png . . .] 3. 总结（conclution) &emsp;&emsp;从上述我们可以看出来 ，装饰者模式用于已经存在的类添加额外的功能，但是它也有缺点，就是它要在设计中加入大量的小类，会造成额外的空间占用。其核心思想还是如下： &emsp;&emsp;多用组合，少用继承。针对接口编程，不针对实现编程。对拓展开放，对修改关闭。github地址：github.com/maskwang520]]></content>
      <categories>
        <category>DesignPattern</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Springboot用WebSocket构建交互式的web应用]]></title>
    <url>%2F2017%2F10%2F12%2FSpringboot%E7%94%A8WebSocket%E6%9E%84%E5%BB%BA%E4%BA%A4%E4%BA%92%E5%BC%8F%E7%9A%84web%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[WebSocket是html5带来的一项重大的特性，使得浏览器与服务端之间真正长连接交互成为了可能，这篇文章会带领大家窥探一下Spring 对WebSocket的支持及使用。 在HTTP/1.0中，默认使用的是短连接。也就是说，浏览器和服务器每进行一次HTTP操作，就建立一次连接，但任务结束就中断连接。但从 HTTP/1.1起，默认使用长连接，用以保持连接特性。使用长连接的HTTP协议，会在响应头有加入这行代码：Connection:keep-alive 在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的 TCP连接不会关闭HTTP协议的长连接和短连接，这两种实质上是TCP协议的长连接和短连接。 项目结构 12345678910111213└── src └── main └── java └── hello └── config └── WebsocketConfig.java └── controller └── GreetingController.java └── message └── Greeting.java └── HelloMessage.java └──test └── pom.xml 1.Maven引入Jar包12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.springboot&lt;/groupId&gt; &lt;artifactId&gt;sprigboot-websocket&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.3.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-websocket&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.webjars&lt;/groupId&gt; &lt;artifactId&gt;webjars-locator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.webjars&lt;/groupId&gt; &lt;artifactId&gt;sockjs-client&lt;/artifactId&gt; &lt;version&gt;1.0.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.webjars&lt;/groupId&gt; &lt;artifactId&gt;stomp-websocket&lt;/artifactId&gt; &lt;version&gt;2.3.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.webjars&lt;/groupId&gt; &lt;artifactId&gt;bootstrap&lt;/artifactId&gt; &lt;version&gt;3.3.7&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.webjars&lt;/groupId&gt; &lt;artifactId&gt;jquery&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 2.编写客户端发送的消息和服务端回复的消息Java类1234567891011121314151617181920212223package hello.messaage;/** * Created by maskwang on 2017/10/12 0012. */public class HelloMessage &#123; String name; public HelloMessage() &#123; &#125; public HelloMessage(String name) &#123; this.name = name; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; 1234567891011121314151617181920212223package hello.messaage;/** * Created by maskwang on 2017/10/12 0012. */public class Greeting &#123; String content; public Greeting() &#123; &#125; public Greeting(String content) &#123; this.content = content; &#125; public String getContent() &#123; return content; &#125; public void setContent(String content) &#123; this.content = content; &#125;&#125; 注意在上面要有默认的构造器，没有的话，则会出现下面问题 这是因为序列化后，如果没有默认的构造器，则会让Springboot的默认序列化Jackson不能构造成原来的对象，反序列化还是需要通过默认的构造器来实现的 。客户端发送HelloMessage,服务端服务以Greeting。 ####3.Websocket配置类12345678910111213141516171819202122232425262728package hello.config;import org.springframework.context.annotation.Configuration;import org.springframework.messaging.simp.config.MessageBrokerRegistry;import org.springframework.web.socket.config.annotation.AbstractWebSocketMessageBrokerConfigurer;import org.springframework.web.socket.config.annotation.EnableWebSocketMessageBroker;import org.springframework.web.socket.config.annotation.StompEndpointRegistry;/** * Created by maskwang on 2017/10/12 0012. */@Configuration@EnableWebSocketMessageBrokerpublic class WebsocketConfig extends AbstractWebSocketMessageBrokerConfigurer &#123; @Override public void configureMessageBroker(MessageBrokerRegistry config) &#123; //客户端接收服务端消息的地址的前缀信息（客户端接受） config.enableSimpleBroker("/topic"); //客户端给服务端发消息的地址的前缀（客户端发送） config.setApplicationDestinationPrefixes("/app"); &#125; //这个方法的作用是添加一个服务端点，来接收客户端的连接。并开启SockJS的支持。 @Override public void registerStompEndpoints(StompEndpointRegistry registry) &#123; registry.addEndpoint("/socket").withSockJS(); &#125;&#125; registry.addEndpoint(“/socket”)表示添加了一个/socket端点，客户端和服务端就可以通过这个端点来进行连接。 withSockJS()的作用是开启SockJS支持 @EnableWebSocketMessageBroker别忘了。 configureMessageBroker(MessageBrokerRegistry config)定义消息代理，也就是服务端和客户端他们之间交换消息的规范。config.enableSimpleBroker(“/topic”);表明客户端接受服务端的消息时候，服务端的请求地址前缀。config.setApplicationDestinationPrefixes(“/app”)表明服务端接受客户端时候，客户端的请求地址前缀。4. 编写业务代码12345678910111213141516171819202122package hello.controller;import hello.messaage.Greeting;import hello.messaage.HelloMessage;import org.springframework.messaging.handler.annotation.MessageMapping;import org.springframework.messaging.handler.annotation.SendTo;import org.springframework.stereotype.Controller;/** * Created by maskwang on 2017/10/12 0012. */@Controllerpublic class GreetingController &#123; @MessageMapping("/hello") //转发给服务端 @SendTo("/topic/greetings") public Greeting greeting(HelloMessage message) throws Exception &#123; Thread.sleep(1000); // simulated delay return new Greeting("Hello, " + message.getName() + "!"); &#125;&#125; @SendTo(“/topic/greetings”)是客户端发起连接后，订阅服务端消息时指定的一个地址，用于接收服务端的返回，也就是服务端返回的消息在客户端在订阅这个地址的消息后，客户端可以收到。定义怎样的客户端。 @MessageMapping(“/hello”)定义这个地址客户端发送的消息就会被映射这样的服务端。也就是客户端寻找那个服务端。定义了什么样的服务端。 理解上面两点很重要，后面都与这有关。 5. 前端代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Hello WebSocket&lt;/title&gt; &lt;link href="/webjars/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet"&gt; &lt;link href="/main.css" rel="stylesheet"&gt; &lt;script src="/webjars/jquery/3.1.0/jquery.min.js"&gt;&lt;/script&gt; &lt;script src="/webjars/sockjs-client/1.0.2/sockjs.min.js"&gt;&lt;/script&gt; &lt;script src="/webjars/stomp-websocket/2.3.3/stomp.min.js"&gt;&lt;/script&gt; &lt;script src="/app.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;noscript&gt;&lt;h2 style="color: #ff0000"&gt;Seems your browser doesn't support Javascript! Websocket relies on Javascript being enabled. Please enable Javascript and reload this page!&lt;/h2&gt;&lt;/noscript&gt;&lt;div id="main-content" class="container"&gt; &lt;div class="row"&gt; &lt;div class="col-md-6"&gt; &lt;form class="form-inline"&gt; &lt;div class="form-group"&gt; &lt;label for="connect"&gt;WebSocket connection:&lt;/label&gt; &lt;button id="connect" class="btn btn-default" type="submit"&gt;Connect&lt;/button&gt; &lt;button id="disconnect" class="btn btn-default" type="submit" disabled="disabled"&gt;Disconnect &lt;/button&gt; &lt;/div&gt; &lt;/form&gt; &lt;/div&gt; &lt;div class="col-md-6"&gt; &lt;form class="form-inline"&gt; &lt;div class="form-group"&gt; &lt;label for="name"&gt;What is your name?&lt;/label&gt; &lt;input type="text" id="name" class="form-control" placeholder="Your name here..."&gt; &lt;/div&gt; &lt;button id="send" class="btn btn-default" type="submit"&gt;Send&lt;/button&gt; &lt;/form&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="row"&gt; &lt;div class="col-md-12"&gt; &lt;table id="conversation" class="table table-striped"&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Greetings&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody id="greetings"&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 编写js1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950var stompClient = null;function setConnected(connected) &#123; $("#connect").prop("disabled", connected); $("#disconnect").prop("disabled", !connected); if (connected) &#123; $("#conversation").show(); &#125; else &#123; $("#conversation").hide(); &#125; $("#greetings").html("");&#125;function connect() &#123; var socket = new SockJS('/socket'); //链接socket stompClient = Stomp.over(socket); stompClient.connect(&#123;&#125;, function (frame) &#123; setConnected(true); console.log('Connected: ' + frame); stompClient.subscribe('/topic/greetings', function (greeting) &#123; showGreeting(JSON.parse(greeting.body).content); &#125;); &#125;);&#125;function disconnect() &#123; if (stompClient !== null) &#123; stompClient.disconnect(); &#125; setConnected(false); console.log("Disconnected");&#125;function sendName() &#123; stompClient.send("/app/hello", &#123;&#125;, JSON.stringify(&#123;'name': $("#name").val()&#125;));&#125;function showGreeting(message) &#123; $("#greetings").append("&lt;tr&gt;&lt;td&gt;" + message + "&lt;/td&gt;&lt;/tr&gt;");&#125;$(function () &#123; $("form").on('submit', function (e) &#123; e.preventDefault(); &#125;); $( "#connect" ).click(function() &#123; connect(); &#125;); $( "#disconnect" ).click(function() &#123; disconnect(); &#125;); $( "#send" ).click(function() &#123; sendName(); &#125;);&#125;); 前端我们需要用到两个js文件：sockjs.js和stomp.js SockJS：SockJS 是一个浏览器上运行的 JavaScript 库，如果浏览器不支持 WebSocket，该库可以模拟对 WebSocket 的支持，实现浏览器和 Web 服务器之间低延迟、全双工、跨域的通讯通道。StompStomp 提供了客户端和代理之间进行广泛消息传输的框架。Stomp 是一个非常简单而且易用的通讯协议实现，尽管代理端的编写可能非常复杂，但是编写一个 Stomp 客户端却是很简单的事情，另外你可以使用 Telnet 来与你的 Stomp 代理进行交互。 开启Socket var socket = new SockJS(‘/socket’); 先构建一个SockJS对象 stompClient = Stomp.over(socket); 用Stomp将SockJS进行协议封装 stompClient.connect()与服务端进行连接，同时有一个回调函数，处理连接成功后的操作信息。发送消息 stompClient.send(“/app/hello”, {}, JSON.stringify({‘name’: $(“#name”).val()}));是客户端向服务端发送消息 stompClient.subscribe(‘/topic/greetings’, function (greeting) { showGreeting(JSON.parse(greeting.body).content); }); //是服务端向客户端发送消息 点击connect后，发动任何message,服务端都会延迟一秒后，回复hello,message! 参考文献 HTTP长连接和短连接 Spring官方websocket例子 Spring WebSocket初探1 (Spring WebSocket入门教程)]]></content>
      <categories>
        <category>Springboot</category>
      </categories>
      <tags>
        <tag>websocket</tag>
        <tag>springboot</tag>
        <tag>web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[弄懂Fail-Safe,Fail-First]]></title>
    <url>%2F2017%2F10%2F08%2F%E5%BC%84%E6%87%82Fail-Safe-Fail-First%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;今天在做算法题的时候，碰到的如下问题，记录下来加深记忆。很多时候我们都有这样一个需求，在迭代的时候（满足某个给定的条件）添加或者删除元素。结果却是等来了java.util.ConcurrentModificationException这个异常，追踪其原因，就是有些容器是Fail-Safe，Fail-First的12345678910111213public class CollectionTest &#123; public static void main(String[] args) &#123; ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;&gt;(); arrayList.add(1); arrayList.add(2); arrayList.add(3); for (int a : arrayList) &#123; if (a == 1) arrayList.remove(a); &#125; System.out.println(arrayList); &#125;&#125; 1. Fail-Safe,Fail-First概念。 在ArrayList的里面有个内部类Itr。当我们获取到迭代器的时候，就会对这个类进行初始化，来看下这个类的源码，分析初始化做了些什么。123456789101112131415161718192021222324252627282930313233343536373839404142private class Itr implements Iterator&lt;E&gt; &#123; int cursor; // index of next element to return int lastRet = -1; // index of last element returned; -1 if no such int expectedModCount = modCount; public boolean hasNext() &#123; return cursor != size; &#125; @SuppressWarnings("unchecked") public E next() &#123; checkForComodification(); int i = cursor; if (i &gt;= size) throw new NoSuchElementException(); Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) throw new ConcurrentModificationException(); cursor = i + 1; return (E) elementData[lastRet = i]; &#125; public void remove() &#123; if (lastRet &lt; 0) throw new IllegalStateException(); checkForComodification(); try &#123; ArrayList.this.remove(lastRet); cursor = lastRet; lastRet = -1; expectedModCount = modCount; &#125; catch (IndexOutOfBoundsException ex) &#123; throw new ConcurrentModificationException(); &#125; &#125; final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException(); &#125; &#125; 在初始化的时候，它会让expectedModCount = modCount，modCount在AbstractList，每次对ArrayList的结构性改变（remove,add）都会使得modCount相应的减1或者加1。来分析下我们刚开始出现问题的代码。当我们获取到迭代器的时候，此时expectedModCount = modCount。当remove的时候，modCount会加1，但是expectedModCount却不变，当执行Itr的next()操作时候，会执行上述源码中的checkForComodification()来检查expectedModCount = modCount，若不相等，则会throw ConcurrentModificationException。所以就不难分析出上述问题。 FailFirst:当我们在迭代获取集合元素的时候，在迭代器创建之后，对集合做一些结构性的改变（remove,add操作)，那么FailFirst容器首先会抛出 ConcurrentModificationException。 2. 如何解决上述问题。12345678910111213public static void main(String[] args) &#123; ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;&gt;(); arrayList.add(1); arrayList.add(2); arrayList.add(3); ArrayList sub=new ArrayList(); for(int a:arrayList)&#123; if(a==1) sub.add(a); &#125; arrayList.removeAll(sub); System.out.println(arrayList); &#125; 上述这个办法好，但是却占额外空间。1234567891011121314public static void main(String[] args) &#123; ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;&gt;(); arrayList.add(1); arrayList.add(2); arrayList.add(3); Iterator&lt;Integer&gt; iterator = arrayList.iterator(); while (iterator.hasNext()) &#123; int a = iterator.next(); if (a == 1) iterator.remove(); &#125; System.out.println(arrayList); &#125; 这样就不占额外的空间，是更好的办法。 iterator.remove()为啥不会抛异常，看看源码1234567891011121314public void remove() &#123; if (lastRet &lt; 0) throw new IllegalStateException(); checkForComodification(); try &#123; ArrayList.this.remove(lastRet); cursor = lastRet; lastRet = -1; expectedModCount = modCount; &#125; catch (IndexOutOfBoundsException ex) &#123; throw new ConcurrentModificationException(); &#125; &#125; expectedModCount = modCount;这句起作用，它删除元素后它会强制满足条件。所以不会抛异常。 3. Fail-Safe的出场 。 将刚开始的代码换成如下的形式,问题迎刃而解。1234567891011121314public static void main(String[] args) &#123; CopyOnWriteArrayList&lt;Integer&gt; arrayList = new CopyOnWriteArrayList&lt;&gt;(); arrayList.add(1); arrayList.add(2); arrayList.add(3); Iterator&lt;Integer&gt; iterator = arrayList.iterator(); while (iterator.hasNext()) &#123; int a = iterator.next(); if (a == 1) arrayList.remove(a); &#125; System.out.println(arrayList); &#125; 像CopyOnWriteArrayList这类容器就属于Fail-Safe容器。当集合结构改变的时候不会抛出异常，这是因为他们只是原始集合的复制，它用snapshot这个数组来保存集合。所以你原始集合的修改只会让原来的引用指向新的数组，而旧的引用还是被迭代器的snapshot所引用。因而他们属于Fail-Safe容器。看看其源码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public boolean add(E e) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; Object[] elements = getArray(); int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len + 1); newElements[len] = e; setArray(newElements); return true; &#125; finally &#123; lock.unlock(); &#125; &#125; private boolean remove(Object o, Object[] snapshot, int index) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; Object[] current = getArray(); int len = current.length; if (snapshot != current) findIndex: &#123; int prefix = Math.min(index, len); for (int i = 0; i &lt; prefix; i++) &#123; if (current[i] != snapshot[i] &amp;&amp; eq(o, current[i])) &#123; index = i; break findIndex; &#125; &#125; if (index &gt;= len) return false; if (current[index] == o) break findIndex; index = indexOf(o, current, index, len); if (index &lt; 0) return false; &#125; Object[] newElements = new Object[len - 1]; System.arraycopy(current, 0, newElements, 0, index); System.arraycopy(current, index + 1, newElements, index, len - index - 1); setArray(newElements); return true; &#125; finally &#123; lock.unlock(); &#125; &#125; 从上面可以看出每次添加元素都是线程安全的，因为加了锁。另外，每添加一个元素，都会把原来的引用指向一个新的数组。所以对他进行操作没问题。所以使用Fail-Safe容器也是一种很好的解决办法。]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>集合</tag>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HeadFirst设计模式2---观察者模式]]></title>
    <url>%2F2017%2F10%2F07%2FHeadFirst%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F2-%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;在我们的开发工作中，经常会遇到这样的问题。例如：对于A，对象B，C在原来引用了A。现在对象A的属性发生了变化，我们的需求是B，C能够同时感应到这种变化。且新增的对象D，也要引用A对象，那如何在不改变原来代码的基础上，如何做到呢。此时，观察者模式就能够很好的解决这个问题。 1. 为何需要观察者模式（why) Defidition:观察者模式定义了对象之间的一对多依赖，这样一来，当一个对象改变状态时，它的所有依赖者都会收到通知并自动更新。 下面通过一个和实例逐步弄清楚什么是观察者模式。 2. 如何实现观察者模式（通过实例来讲解how） 某气象站有这样一个应用：它实时检测当地温度，适度，压强。并让第一号布告板，第二号布告板，第三号布告板或者其他第三方接入Api都能实时更新相应的数据。气象站提供的数据结构如下。123456public class WeatherData &#123; float temp; float humidity; float pressture;//省略get,set方法&#125; 我们想到的办法就是让第一号布告板，第二号布告板，第三号布告板或者其他第三方接入Api都成为气象站的观察者，他们只需要在气象站注册，当气象站的数据发生变化的时候，会遍历每个观察者，调用update（）实现更新操作。step1:定义抽象接口1234567891011121314151617181920public interface Subject &#123; //主题，即气象站的抽象接口 //注册观察者 public void registerObserver(Observer o); //取消观察者 public void removeObserver(Observer o); //通知观察者执行更新操作 public void notifyObservers();&#125;public interface Observer &#123; //更新操作，等待Subject调用就实现了通知 public void update(float temp,float humidy,float pressure);&#125;public interface DisplayElement &#123; //对更新进行展示 public void display();&#125; 上述是接口，便于代码重用和面向接口编程，而不是面向实现编程。step2:实现具体的类123456789101112131415161718192021222324252627282930313233343536373839404142434445public class WeatherData implements Subject &#123; private ArrayList&lt;Observer&gt; observers; private float temperature; private float humidity; private float pressture; public WeatherData()&#123; observers=new ArrayList(); &#125; @Override public void registerObserver(Observer o) &#123; observers.add(o); &#125; @Override public void removeObserver(Observer o) &#123; int i=observers.indexOf(o); if(i&gt;=0) observers.remove(i); &#125; @Override public void notifyObservers() &#123; observers.stream().forEach((observer)-&gt;observer.update(temperature,humidity,pressture)); &#125; public void measurementsChanged()&#123;//通知 notifyObservers(); &#125; //属性改变了 public void setMeasurements(float temperature,float humidity,float pressture)&#123; this.temperature=temperature; this.humidity=humidity; this.pressture=pressture; measurementsChanged(); &#125;&#125; step3:Observer这里只提供一种实现，剩下的可以同样生成。123456789101112131415161718192021222324252627282930** * Created by maskwang on 2017/10/5 0005. * 时间原因这里只提供一种实现 */public class CurrentConditionsDisplay implements Observer,DisplayElement &#123; //这个观察者只在乎以下两个属性 private float temperature; private float humidity; private Subject weatherData; public CurrentConditionsDisplay(Subject weatherData) &#123; this.weatherData = weatherData; weatherData.registerObserver(this);//注册 &#125; @Override public void display() &#123; System.out.println(temperature+"**"+humidity); &#125; @Override public void update(float temp, float humidy, float pressure) &#123; this.humidity=humidy; this.temperature=temp; display(); &#125;&#125; step4:测试类12345678910111213public class WeatherStation &#123; public static void main(String[] args) &#123; WeatherData weatherData=new WeatherData(); //订阅那个Object CurrentConditionsDisplay currentConditionsDisplay=new CurrentConditionsDisplay(weatherData); weatherData.setMeasurements(80,65,30.2f); weatherData.setMeasurements(82,70,28.4f); weatherData.setMeasurements(83,72,27.5f); &#125;&#125; Uml类图如下： 结果如下： 可以看到每次Subject变化，Observer跟着变化。 3. 观察者模式总结（conclusion） 以上实例可以看出来，观察者模式实现了Obseerver和Subject的解耦，Subject可以增删任意Observer,而Observer可以订阅任意的Subject。很好的满足了这种需求。这让我activemq，它其中就有一种发布订阅模式，在这里面生产者产生的消息，都能理解被消费者立即订阅到。可以看的出来这种思想应用的还是很广的。附上对应的github地址： https://github.com/maskwang520/designpattern.git]]></content>
      <categories>
        <category>DesignPattern</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HeadFirst设计模式1-策略模式]]></title>
    <url>%2F2017%2F10%2F07%2FHeadFirst%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F1-%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;作者在看HeadFirst设计模式，把整个学习过程记录下来，方便以后回顾，也可以与大家交流，欢迎拍板。整个系列每篇文章围绕why,how,conclusion这三方面展开。 1. 为什么需要策略模式 考虑到如下一个场景，你构造一个Duck的SuperClass,以后各种各样的鸭子都继承该SuperClass ,代码实现应该如下。12345678910111213public class Duck &#123; public void quack()&#123; //会叫 System.out.println("I can quack"); &#125; public void swim()&#123; //会游泳 System.out.println("I can swim"); &#125; public void play()&#123; //外表 System.out.println("I am a special duck with good look"); &#125;&#125; 具体的实现类如下123456789101112public class GreeHeadDuck extends Duck &#123; //绿头鸭 @Override public void play()&#123; System.out.println("I am green duck"); &#125;&#125;public class RedHeadDuck extends Duck&#123; //红头鸭 @Override public void play()&#123; System.out.println("I am red duck"); &#125;&#125; 上面这样看起来也没毛病啊，但是它有个问题就是，当给SuperClass加上fly()方法后，表示每个子类都会飞。即便是我后来的子类不能飞，它也可以fly。此时，我们可能会想到，覆盖fly()方法，方法里面什么都不做。但是问题还是很突出。原因如下： 代码在多个子类中重复。不管是什么类型的鸭子，都会继承来SuperClass的所有属性和方法，这其中有些子类根本就不具备。 运行时的行为不容易改变。我想让某个鸭子换个叫声，在不动SuperClass的情况下做不到。 很难知道所有鸭子共同的行为。比如fly方法，有些鸭子不具备，但是还是在父类中。 改一发动全身，我上面还是只添加fly(),有些鸭子不会飞，但是要覆盖方法。 我们接着可能会采用如下的解决办法，把fly,display从超类中抽出来，放进一个Flayable接口中。把quack()抽出来，放进Quackable接口中，代码如下。123456public interface Quackable &#123; //会叫的接口 public void quack();&#125;public interface Flyable &#123; //会飞接口 public void fly();&#125; 这样对于多个会飞Duck子类，每个子类都有一个实现Flyable()的类，在里面覆写fly()方法，会造成太多Flyable()的子类，无法复用。其次，还不能动态改变fly行为，因为已经写死啦。此时，设计原则就出来了，即：找出应用之中可能需要变化之处，把他们独立出来，不要和那些不需要变化的代码混到一起。 2. 如何使用策略模式 解决上述问题的根本是分开变化和不会变化的部分。Duck类中的fly(),quack()会随着鸭子的不同而改变，那我们将它们从Duck类中取出来，建立一组新类来代表每个行为。此时，设计原则就应用上了即，针对接口编程，而不是针对实现编程 这句话的理解在这里就是针对超类编程。前面我们设计 Quackable，Flyable，然后让具体的类去实现这两个接口，这样，就是针对实现编程，不利于动态修改和以后的拓展。因此，我们编写两个FlyBehavior,QuackBehavior两个接口，以及他们的实现类，这样，我们把FlyBehavior和QuackBehavior作为超类的属性，这个具体的实现通过set方法通过set()传递进去，这样实现面向接口编程，可以动态改变，也可以复用代码。代码实现如下：行为接口123456public interface FlyBehavior &#123; public void fly();&#125;public interface QuackBehavior &#123; public void quack();&#125; 实现类12345678910111213141516171819202122232425public class FlyNoWay implements FlyBehavior &#123; //不能飞 @Override public void fly() &#123; System.out.println("I can FlyNoWay"); &#125;&#125;public class FlyWithWins implements FlyBehavior &#123; //用翅膀飞 @Override public void fly() &#123; System.out.println("i can fly with wins"); &#125;&#125;public class Quack implements QuackBehavior &#123; //一般的叫 @Override public void quack() &#123; System.out.println("quack"); &#125;&#125;public class Squack implements QuackBehavior &#123; //嘶叫 @Override public void quack() &#123; System.out.println("squack"); &#125;&#125; 把基本接口作为超类的属性成员，面向接口编程12345678910111213141516171819202122232425262728public class Duck &#123; private FlyBehavior flyBehavior; //代理类，组合模式 private QuackBehavior quackBehavior; public void fly()&#123; flyBehavior.fly(); &#125; public void quack()&#123; quackBehavior.quack(); &#125; public void setFlyBehavior(FlyBehavior flyBehavior) &#123; this.flyBehavior = flyBehavior; &#125; public void setQuackBehavior(QuackBehavior quackBehavior) &#123; this.quackBehavior = quackBehavior; &#125; public void swim()&#123; //会游泳 System.out.println("I can swim"); &#125; public void play()&#123; //外表 System.out.println("I am a special duck with good look"); &#125;&#125; 测试类如下123456789public class Main &#123; public static void main(String[] args) &#123; Duck duck=new Duck(); duck.setFlyBehavior(new FlyNoWay()); duck.fly(); duck.setFlyBehavior(new FlyWithWins()); duck.fly(); &#125;&#125; 结果如下图 总结：上述做法的好处，面对不同飞行类型，可以在不修改Duck的基础上实现，这就是策略模式，根据你传入进来的具体实现类，执行不同的行为，这里关键就是运用多态这一特点。其次，不同的实现类可以复用，以前针对每个子类都有实现类，现在同一类型的都可以采用同一个实现类。 3. 结论 策略模式定义了算法族，分别封装起来，让它们之间可以互相替换，此模式让算法的变化独立于使用算法的客户，简单来说，就是定义了基础接口封装在类属性里面，可以根据不同的实现类，动态的改变行为。]]></content>
      <categories>
        <category>DesignPattern</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
        <tag>java</tag>
      </tags>
  </entry>
</search>